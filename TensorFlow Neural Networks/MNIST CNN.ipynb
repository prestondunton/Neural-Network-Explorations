{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import timedelta\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/MNIST',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_conv_weights(weights, input_channel=0):\n",
    "    # Assume weights are TensorFlow ops for 4-dim variables\n",
    "    # e.g. weights_conv1 or weights_conv2.\n",
    "    \n",
    "    # Retrieve the values of the weight-variables from TensorFlow.\n",
    "    # A feed-dict is not necessary because nothing is calculated.\n",
    "    w = sess.run(weights)\n",
    "\n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across\n",
    "    # the images so they can be compared with each other.\n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "\n",
    "    # Number of filters used in the conv. layer.\n",
    "    num_filters = w.shape[3]\n",
    "\n",
    "    # Number of grids to plot.\n",
    "    # Rounded-up, square-root of the number of filters.\n",
    "    num_grids = math.ceil(math.sqrt(num_filters))\n",
    "    \n",
    "    # Create figure with a grid of sub-plots.\n",
    "    fig, axes = plt.subplots(num_grids, num_grids)\n",
    "\n",
    "    # Plot all the filter-weights.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only plot the valid filter-weights.\n",
    "        if i<num_filters:\n",
    "            # Get the weights for the i'th filter of the input channel.\n",
    "            # See new_conv_layer() for details on the format\n",
    "            # of this 4-dim tensor.\n",
    "            img = w[:, :, input_channel, i]\n",
    "\n",
    "            # Plot image.\n",
    "            ax.imshow(img, vmin=w_min, vmax=w_max,\n",
    "                      interpolation='nearest', cmap='seismic')\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper Parameters and Structure\n",
    "# input > conv > relu > max pooling > flattened > fully connected > sigmoid\n",
    "\n",
    "batchSize = 64 #number of examples to use during training\n",
    "\n",
    "numberOfImages = 55000\n",
    "imgSize = 28\n",
    "imgShape = (imgSize,imgSize)\n",
    "imgShapeFlat = imgSize*imgSize\n",
    "\n",
    "filterSize1 = 5\n",
    "filterShape1 = (filterSize1,filterSize1)\n",
    "filterShapeFlat1 = filterSize1*filterSize1\n",
    "numberOfFilters1 = 16\n",
    "\n",
    "filterSize2 = 5\n",
    "filterShape2 = (filterSize2,filterSize2)\n",
    "filterShapeFlat2 = filterSize2*filterSize2\n",
    "numberOfFilters2 = 36\n",
    "\n",
    "stride = (1,1) # y then x\n",
    "strideShape = [1,stride[0],stride[1],1] #1s on sides are for image number and channel respectively\n",
    "\n",
    "poolingStride = (2,2)\n",
    "poolingStrideShape = [1,poolingStride[0],poolingStride[1],1]\n",
    "\n",
    "numberOfChannels = 1 #this is the color depth. greyscale is 1, rgb is 3 etc. What is binary? probably 1\n",
    "\n",
    "fcSize = 128\n",
    "\n",
    "initSeed = tf.set_random_seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingData = mnist.train.images.reshape(numberOfImages,imgSize,imgSize,numberOfChannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3013bd358>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e301365f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainingData[5].reshape(imgShape),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Input'):\n",
    "    x = tf.placeholder(tf.float32,[None,28,28,1])\n",
    "with tf.name_scope('Output'):\n",
    "    y = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Convolution1'):\n",
    "    with tf.name_scope('Filters1'):\n",
    "        filters1 = tf.Variable(tf.random_normal([filterSize1,filterSize1,numberOfChannels,numberOfFilters1],seed=initSeed))\n",
    "    activationMap1 = tf.nn.conv2d(x,filters1,strideShape,'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('MaxPooling1'):\n",
    "    maxPoolLayer1 = tf.nn.max_pool(activationMap1,poolingStrideShape,poolingStrideShape,'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('ReLU1'):\n",
    "    reluLayer1 = tf.nn.relu(maxPoolLayer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Convolution2'):\n",
    "    with tf.name_scope('Filters2'):\n",
    "        filters2 = tf.Variable(tf.random_normal([filterSize2,filterSize2,numberOfFilters1,numberOfFilters2],seed=initSeed))\n",
    "    activationMap2 = tf.nn.conv2d(reluLayer1,filters2,strideShape,'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('MaxPooling2'):\n",
    "    maxPoolLayer2 = tf.nn.max_pool(activationMap2,poolingStrideShape,poolingStrideShape,'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('ReLU2'):\n",
    "    reluLayer2 = tf.nn.relu(maxPoolLayer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flattening_1/Reshape:0\", shape=(?, 1764), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Flattening'):\n",
    "    num_features = reluLayer2.shape[1:4].num_elements() # same as maxPoolLayer.shape[1]*maxPoolLayer.shape[2]*maxPoolLayer.shape[3] but that <- wont work for some reason\n",
    "    flatLayer = tf.reshape(reluLayer2,[-1,(num_features)])\n",
    "    print(flatLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('FC'):\n",
    "    with tf.name_scope('Weights'):\n",
    "        weights1 = tf.Variable(tf.random_normal([num_features,fcSize],seed=initSeed))\n",
    "    with tf.name_scope('Biases'):\n",
    "        biases1 = tf.Variable(tf.random_normal([fcSize],seed=initSeed))\n",
    "    activity1 = tf.matmul(flatLayer,weights1)\n",
    "    activation1 = tf.add(activity1,biases1)\n",
    "    relu1 = tf.nn.relu(activation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Output'):\n",
    "    with tf.name_scope('Weights'):\n",
    "        weights2 = tf.Variable(tf.random_normal([fcSize,10],seed=initSeed))\n",
    "    with tf.name_scope('Biases'):\n",
    "        biases2 = tf.Variable(tf.random_normal([10],seed=initSeed))\n",
    "    activity2 = tf.matmul(relu1,weights2) + biases2\n",
    "    #output = tf.nn.relu(activity2)\n",
    "    yHat = tf.argmax(activity2,dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Loss_And_Training'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=activity2,labels=y))\n",
    "    training = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    yTrue = tf.argmax(y,dimension=1)\n",
    "    truthTensor = tf.equal(yHat,tf.cast(yTrue,tf.int64))\n",
    "    accuracy = tf.reduce_mean(tf.cast(truthTensor, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Init'):\n",
    "    init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "currentFilters = filters1\n",
    "#plot_conv_weights(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Current Accuracy: 6.25 % Time Elapsed: 0:00:00\n",
      "Iteration: 200 Current Accuracy: 20.3125 % Time Elapsed: 0:00:25\n",
      "Iteration: 400 Current Accuracy: 40.625 % Time Elapsed: 0:00:50\n",
      "Iteration: 600 Current Accuracy: 59.375 % Time Elapsed: 0:01:20\n",
      "Iteration: 800 Current Accuracy: 59.375 % Time Elapsed: 0:01:46\n",
      "Iteration: 1000 Current Accuracy: 60.9375 % Time Elapsed: 0:02:13\n",
      "Iteration: 1200 Current Accuracy: 70.3125 % Time Elapsed: 0:02:39\n",
      "Iteration: 1400 Current Accuracy: 67.1875 % Time Elapsed: 0:03:04\n",
      "Iteration: 1600 Current Accuracy: 81.25 % Time Elapsed: 0:03:29\n",
      "Iteration: 1800 Current Accuracy: 78.125 % Time Elapsed: 0:03:53\n",
      "Iteration: 2000 Current Accuracy: 71.875 % Time Elapsed: 0:04:19\n",
      "Iteration: 2200 Current Accuracy: 85.9375 % Time Elapsed: 0:04:45\n",
      "Iteration: 2400 Current Accuracy: 78.125 % Time Elapsed: 0:05:10\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter(\"C:/Users/Preston/Anaconda3/envs/tensorflow/tensorboard_graphs\", sess.graph)\n",
    "startTime = time.time()\n",
    "for i in range(0,2600):\n",
    "    xBatch, yBatch = mnist.train.next_batch(batchSize)\n",
    "    xBatch = xBatch.reshape(batchSize,28,28,1)\n",
    "    \n",
    "    xTestBatch, yTestBatch = mnist.test.next_batch(batchSize)\n",
    "    xTestBatch = xTestBatch.reshape(batchSize,28,28,1)\n",
    "    \n",
    "    sess.run(training,{x:xBatch,y:yBatch})\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print('Iteration:',i,'Current Accuracy:',sess.run(accuracy,{x:xTestBatch,y:yTestBatch})*100,'%','Time Elapsed:',timedelta(seconds=int(round(time.time()-startTime))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8137.0\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for i in range(0,mnist.test.labels.shape[0]):\n",
    "    prediction = int(sess.run(yHat,{x:mnist.test.images[i:i+1].reshape(1,28,28,1)}))\n",
    "    if np.argmax(mnist.test.labels[i]) != prediction:\n",
    "        errors += 1\n",
    "print((1-(errors/mnist.test.labels.shape[0]))*mnist.test.labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3043ce1d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e301389860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[i].reshape(imgShape),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(mnist.test.labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
