{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "from datetime import timedelta\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/MNIST',one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initSeed = tf.set_random_seed(420)\n",
    "gHiddenSize = 30\n",
    "\n",
    "dFilterSize1 = 5\n",
    "dFilterShape1 = (dFilterSize1,dFilterSize1)\n",
    "dNumberOfFilters1 = 32\n",
    "\n",
    "dFilterSize2 = 5\n",
    "dFilterShape2 = (dFilterSize1,dFilterSize1)\n",
    "dNumberOfFilters2 = 64\n",
    "\n",
    "dStride = (1,1) # y then x\n",
    "dStrideShape = [1,dStride[0],dStride[1],1] #1s on sides are for image number and channel respectively\n",
    "\n",
    "dPoolingStride = (2,2)\n",
    "dPoolingStrideShape = [1,dPoolingStride[0],dPoolingStride[1],1]\n",
    "\n",
    "dFCSize = 1024\n",
    "\n",
    "\n",
    "gFilterSize1 = 3\n",
    "gFilterShape1 = (gFilterSize1,gFilterSize1)\n",
    "gNumberOfFilters1 = 50\n",
    "\n",
    "gFilterSize2 = 3\n",
    "gFilterShape2 = (gFilterSize2,gFilterSize2)\n",
    "gNumberOfFilters2 = 25\n",
    "\n",
    "gFilterSize3 = 3\n",
    "\n",
    "gStride = (2,2) # y then x\n",
    "gStrideShape = [1,gStride[0],gStride[1],1] #1s on sides are for image number and channel respectively\n",
    "\n",
    "gPoolingStride = (2,2)\n",
    "gPoolingStrideShape = [1,gPoolingStride[0],gPoolingStride[1],1]\n",
    "\n",
    "\n",
    "numberOfChannels = 1 #this is the color depth. greyscale is 1, rgb is 3 etc. What is binary? probably 1\n",
    "batchSize = 50\n",
    "imgSize = 784\n",
    "imgWidth = 28\n",
    "zSize = 100\n",
    "digit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingImages = np.zeros((1,784),dtype=np.float32)\n",
    "for i in range(0,mnist.train.images.shape[0]):\n",
    "    if mnist.train.labels[i] == digit:\n",
    "        trainingImages = np.concatenate((trainingImages,np.reshape(mnist.train.images[i],(1,784))),axis=0)\n",
    "trainingImages = np.delete(trainingImages,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,28,28,1])\n",
    "z = tf.placeholder(tf.float32,[None,zSize])\n",
    "g = tf.placeholder(tf.float32,[None,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights(nameOfVariable, shapeOfVariable):\n",
    "    return tf.Variable(tf.truncated_normal(stddev=0.05,shape=shapeOfVariable), name=nameOfVariable)\n",
    "def biases(nameOfVariable, shapeOfVariable):\n",
    "    return tf.Variable(tf.truncated_normal(stddev=0.05,shape=shapeOfVariable), name=nameOfVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Generator'): # in [batchSize,zSize] out [batchSize,imageSize]\n",
    "    gw0 = weights('gw0',[zSize, 3136])\n",
    "    gw1 = weights('gw1',[gFilterSize1, gFilterSize1, numberOfChannels,gNumberOfFilters1])\n",
    "    gw2 = weights('gw2',[gFilterSize2, gFilterSize2, gNumberOfFilters1,gNumberOfFilters2])\n",
    "    gw3 = weights('gw3',[gFilterSize3, gFilterSize3, gNumberOfFilters2,1])\n",
    "\n",
    "    gb0 = biases('gb0',[3136])\n",
    "    gb1 = biases('gb1',[gNumberOfFilters1])\n",
    "    gb2 = biases('gb2',[gNumberOfFilters2])\n",
    "    gb3 = biases('gb3',[1])\n",
    "    \n",
    "    def generator(zNoise):      \n",
    "        g0 = tf.matmul(zNoise,gw0) + gb0\n",
    "        g0 = tf.reshape(g0, [-1, 56, 56, 1])\n",
    "        g0 = tf.nn.relu(g0)\n",
    "        \n",
    "        g1 = tf.nn.conv2d(g0,gw1,gStrideShape,'SAME')\n",
    "        g1 = tf.nn.relu(g1)\n",
    "        g1 = g1 + gb1\n",
    "        g1 = tf.image.resize_images(g1, [56,56])\n",
    "        \n",
    "        g2 = tf.nn.conv2d(g1,gw2,gStrideShape,'SAME')\n",
    "        g2 = tf.nn.relu(g2)\n",
    "        g2 = g2 + gb2\n",
    "        g2 = tf.image.resize_images(g2, [56,56])\n",
    "        \n",
    "        g3 = tf.nn.conv2d(g2,gw3,gStrideShape,'SAME')\n",
    "        g3 = tf.nn.relu(g3)\n",
    "        g3 = g3 + gb3\n",
    "        g3 = tf.nn.sigmoid(g3)\n",
    "        \n",
    "        return g3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Discriminator'): # in [batchSize,28,28,1] out [batchSize,1]\n",
    "    dw0 = weights('dw0', [dFilterSize1,dFilterSize1,numberOfChannels,dNumberOfFilters1])\n",
    "    dw1 = weights('dw1', [dFilterSize2,dFilterSize2,dNumberOfFilters1,dNumberOfFilters2])\n",
    "    dw2 = weights('dw2', [3136,dFCSize])\n",
    "    dw3 = weights('dw3', [dFCSize,1])\n",
    "    \n",
    "    db0 = biases('db0', [batchSize,imgWidth,imgWidth,dNumberOfFilters1])\n",
    "    db1 = biases('db1', [batchSize,int(imgWidth/dPoolingStride[0]),int(imgWidth/dPoolingStride[1]),dNumberOfFilters2])\n",
    "    db2 = biases('db2', [dFCSize])\n",
    "    \n",
    "    def discriminator(inputData):\n",
    "        d0 = tf.nn.conv2d(inputData,dw0,dStrideShape,'SAME')\n",
    "        d0 = d0 + db0\n",
    "        d0 = tf.nn.max_pool(d0,dPoolingStrideShape,dPoolingStrideShape,'SAME')\n",
    "        d0 = tf.nn.relu(d0)\n",
    "        \n",
    "        d1 = tf.nn.conv2d(d0,dw1,dStrideShape,'SAME')\n",
    "        d1 = d1 + db1\n",
    "        d1 = tf.nn.max_pool(d1,dPoolingStrideShape,dPoolingStrideShape,'SAME')\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        \n",
    "        num_features = d1.shape[1:4].num_elements()\n",
    "        d2 = tf.reshape(d1,[-1,(num_features)])\n",
    "        \n",
    "        d3 = tf.nn.softplus(tf.add(tf.matmul(d2,dw2),db2))\n",
    "        d4 = tf.nn.sigmoid(tf.matmul(d3,dw3))\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gz = generator(z)\n",
    "dx = discriminator(x)\n",
    "dg = discriminator(gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gLoss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dg, labels=tf.ones_like(dg)))\n",
    "dLossOfReal = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dx, labels=tf.ones_like(dx)))\n",
    "dLossOfFake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dg, labels=tf.zeros_like(dg)))\n",
    "dLoss = dLossOfReal + dLossOfFake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDOptimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "AdamOptimizer = tf.train.AdamOptimizer(0.0001)\n",
    "\n",
    "trainDReal = SGDOptimizer.minimize(dLossOfReal,var_list=[dw0,dw1,dw2,dw3,db0,db1,db2])\n",
    "trainDFake = SGDOptimizer.minimize(dLossOfFake,var_list=[dw0,dw1,dw2,dw3,db0,db1,db2])\n",
    "trainD = SGDOptimizer.minimize(dLoss,var_list=[dw0,dw1,dw2,dw3,db0,db1,db2])\n",
    "trainG = SGDOptimizer.minimize(gLoss,var_list=[gw0,gw1,gw2,gw3,gb0,gb1,gb2,gb3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newXBatch(size):\n",
    "    xBatch = np.zeros((1,28,28,1),dtype=np.float32)\n",
    "    while xBatch.shape[0] != size + 1:\n",
    "        xBatch = np.concatenate((xBatch,trainingImages[random.randint(0,len(trainingImages)-1)].reshape(1,28,28,1)),axis=0)    \n",
    "    xBatch = np.delete(xBatch,0,0)\n",
    "    return xBatch #Not good\n",
    "\n",
    "def newZBatch(size):\n",
    "    return sess.run(tf.random_normal(shape=[size,zSize],seed=initSeed))\n",
    "\n",
    "def newGBatch(size):\n",
    "    return sess.run(generator(z,size),{z:newZBatch(size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "#saver.restore(sess, 'C:\\Preston\\MNIST GAN\\mnistGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 gLoss: 0.551915 averageDLoss 0.705098927021 dLossOfReal: 0.552513 dLossOfFake: 0.857685 Time Elapsed: 0:00:06\n",
      "Iteration: 1 gLoss: 0.552097 averageDLoss 0.704173564911 dLossOfReal: 0.550909 dLossOfFake: 0.857438 Time Elapsed: 0:00:13\n",
      "Iteration: 2 gLoss: 0.552284 averageDLoss 0.705464363098 dLossOfReal: 0.553746 dLossOfFake: 0.857183 Time Elapsed: 0:00:20\n",
      "Iteration: 3 gLoss: 0.552469 averageDLoss 0.705132842064 dLossOfReal: 0.553336 dLossOfFake: 0.85693 Time Elapsed: 0:00:26\n",
      "Iteration: 4 gLoss: 0.552655 averageDLoss 0.705453813076 dLossOfReal: 0.554226 dLossOfFake: 0.856682 Time Elapsed: 0:00:32\n",
      "Iteration: 5 gLoss: 0.552839 averageDLoss 0.705003857613 dLossOfReal: 0.553577 dLossOfFake: 0.85643 Time Elapsed: 0:00:39\n",
      "Iteration: 6 gLoss: 0.553023 averageDLoss 0.705631017685 dLossOfReal: 0.555077 dLossOfFake: 0.856185 Time Elapsed: 0:00:45\n",
      "Iteration: 7 gLoss: 0.553203 averageDLoss 0.704388380051 dLossOfReal: 0.55284 dLossOfFake: 0.855937 Time Elapsed: 0:00:51\n",
      "Iteration: 8 gLoss: 0.553388 averageDLoss 0.704717516899 dLossOfReal: 0.553745 dLossOfFake: 0.85569 Time Elapsed: 0:00:57\n",
      "Iteration: 9 gLoss: 0.553569 averageDLoss 0.704765319824 dLossOfReal: 0.554086 dLossOfFake: 0.855444 Time Elapsed: 0:01:04\n",
      "Iteration: 10 gLoss: 0.55375 averageDLoss 0.70513188839 dLossOfReal: 0.555063 dLossOfFake: 0.8552 Time Elapsed: 0:01:10\n",
      "Iteration: 11 gLoss: 0.553927 averageDLoss 0.704380512238 dLossOfReal: 0.553805 dLossOfFake: 0.854956 Time Elapsed: 0:01:17\n",
      "Iteration: 12 gLoss: 0.554108 averageDLoss 0.704429507256 dLossOfReal: 0.554143 dLossOfFake: 0.854716 Time Elapsed: 0:01:23\n",
      "Iteration: 13 gLoss: 0.554286 averageDLoss 0.704346120358 dLossOfReal: 0.55422 dLossOfFake: 0.854472 Time Elapsed: 0:01:29\n",
      "Iteration: 14 gLoss: 0.554466 averageDLoss 0.703631341457 dLossOfReal: 0.553031 dLossOfFake: 0.854232 Time Elapsed: 0:01:36\n",
      "Iteration: 15 gLoss: 0.554643 averageDLoss 0.703913450241 dLossOfReal: 0.553836 dLossOfFake: 0.853991 Time Elapsed: 0:01:42\n",
      "Iteration: 16 gLoss: 0.55482 averageDLoss 0.70472574234 dLossOfReal: 0.555699 dLossOfFake: 0.853753 Time Elapsed: 0:01:48\n",
      "Iteration: 17 gLoss: 0.555 averageDLoss 0.704236984253 dLossOfReal: 0.554966 dLossOfFake: 0.853508 Time Elapsed: 0:01:54\n",
      "Iteration: 18 gLoss: 0.555179 averageDLoss 0.703346967697 dLossOfReal: 0.553423 dLossOfFake: 0.853271 Time Elapsed: 0:02:01\n",
      "Iteration: 19 gLoss: 0.555353 averageDLoss 0.704579591751 dLossOfReal: 0.556123 dLossOfFake: 0.853037 Time Elapsed: 0:02:07\n",
      "Iteration: 20 gLoss: 0.555533 averageDLoss 0.705233216286 dLossOfReal: 0.557673 dLossOfFake: 0.852793 Time Elapsed: 0:02:13\n",
      "Iteration: 21 gLoss: 0.555706 averageDLoss 0.704465150833 dLossOfReal: 0.55637 dLossOfFake: 0.852561 Time Elapsed: 0:02:20\n",
      "Iteration: 22 gLoss: 0.555881 averageDLoss 0.703742921352 dLossOfReal: 0.55516 dLossOfFake: 0.852326 Time Elapsed: 0:02:26\n",
      "Iteration: 23 gLoss: 0.556057 averageDLoss 0.70498919487 dLossOfReal: 0.55789 dLossOfFake: 0.852089 Time Elapsed: 0:02:32\n",
      "Iteration: 24 gLoss: 0.556231 averageDLoss 0.704233884811 dLossOfReal: 0.556613 dLossOfFake: 0.851854 Time Elapsed: 0:02:39\n",
      "Iteration: 25 gLoss: 0.556405 averageDLoss 0.70397734642 dLossOfReal: 0.556335 dLossOfFake: 0.85162 Time Elapsed: 0:02:45\n",
      "Iteration: 26 gLoss: 0.556579 averageDLoss 0.704050540924 dLossOfReal: 0.556715 dLossOfFake: 0.851386 Time Elapsed: 0:02:51\n",
      "Iteration: 27 gLoss: 0.556751 averageDLoss 0.70495146513 dLossOfReal: 0.558747 dLossOfFake: 0.851156 Time Elapsed: 0:02:57\n",
      "Iteration: 28 gLoss: 0.556924 averageDLoss 0.704607367516 dLossOfReal: 0.55829 dLossOfFake: 0.850925 Time Elapsed: 0:03:04\n",
      "Iteration: 29 gLoss: 0.557094 averageDLoss 0.704553246498 dLossOfReal: 0.558414 dLossOfFake: 0.850693 Time Elapsed: 0:03:10\n",
      "Iteration: 30 gLoss: 0.557265 averageDLoss 0.704557359219 dLossOfReal: 0.55865 dLossOfFake: 0.850465 Time Elapsed: 0:03:17\n",
      "Iteration: 31 gLoss: 0.557437 averageDLoss 0.70341950655 dLossOfReal: 0.556603 dLossOfFake: 0.850236 Time Elapsed: 0:03:23\n",
      "Iteration: 32 gLoss: 0.557608 averageDLoss 0.703686535358 dLossOfReal: 0.557368 dLossOfFake: 0.850006 Time Elapsed: 0:03:29\n",
      "Iteration: 33 gLoss: 0.557777 averageDLoss 0.703192770481 dLossOfReal: 0.556606 dLossOfFake: 0.849779 Time Elapsed: 0:03:36\n",
      "Iteration: 34 gLoss: 0.557946 averageDLoss 0.703938484192 dLossOfReal: 0.558324 dLossOfFake: 0.849553 Time Elapsed: 0:03:42\n",
      "Iteration: 35 gLoss: 0.558116 averageDLoss 0.703318893909 dLossOfReal: 0.557312 dLossOfFake: 0.849326 Time Elapsed: 0:03:48\n",
      "Iteration: 36 gLoss: 0.558284 averageDLoss 0.704106748104 dLossOfReal: 0.559113 dLossOfFake: 0.8491 Time Elapsed: 0:03:55\n",
      "Iteration: 37 gLoss: 0.558451 averageDLoss 0.703532576561 dLossOfReal: 0.558188 dLossOfFake: 0.848877 Time Elapsed: 0:04:01\n",
      "Iteration: 38 gLoss: 0.558619 averageDLoss 0.703516721725 dLossOfReal: 0.558378 dLossOfFake: 0.848656 Time Elapsed: 0:04:07\n",
      "Iteration: 39 gLoss: 0.558787 averageDLoss 0.704262018204 dLossOfReal: 0.560094 dLossOfFake: 0.84843 Time Elapsed: 0:04:14\n",
      "Iteration: 40 gLoss: 0.558951 averageDLoss 0.703226566315 dLossOfReal: 0.558245 dLossOfFake: 0.848209 Time Elapsed: 0:04:20\n",
      "Iteration: 41 gLoss: 0.559121 averageDLoss 0.703673958778 dLossOfReal: 0.559364 dLossOfFake: 0.847984 Time Elapsed: 0:04:26\n",
      "Iteration: 42 gLoss: 0.559288 averageDLoss 0.703055620193 dLossOfReal: 0.55835 dLossOfFake: 0.847761 Time Elapsed: 0:04:33\n",
      "Iteration: 43 gLoss: 0.559455 averageDLoss 0.703422665596 dLossOfReal: 0.559307 dLossOfFake: 0.847538 Time Elapsed: 0:04:39\n",
      "Iteration: 44 gLoss: 0.559617 averageDLoss 0.703299403191 dLossOfReal: 0.559275 dLossOfFake: 0.847324 Time Elapsed: 0:04:46\n",
      "Iteration: 45 gLoss: 0.559782 averageDLoss 0.703165471554 dLossOfReal: 0.559229 dLossOfFake: 0.847102 Time Elapsed: 0:04:52\n",
      "Iteration: 46 gLoss: 0.559945 averageDLoss 0.703325748444 dLossOfReal: 0.559768 dLossOfFake: 0.846884 Time Elapsed: 0:04:58\n",
      "Iteration: 47 gLoss: 0.560109 averageDLoss 0.703038990498 dLossOfReal: 0.559414 dLossOfFake: 0.846664 Time Elapsed: 0:05:05\n",
      "Iteration: 48 gLoss: 0.560271 averageDLoss 0.703074276447 dLossOfReal: 0.559702 dLossOfFake: 0.846447 Time Elapsed: 0:05:11\n",
      "Iteration: 49 gLoss: 0.560439 averageDLoss 0.702905535698 dLossOfReal: 0.559583 dLossOfFake: 0.846228 Time Elapsed: 0:05:18\n",
      "Iteration: 50 gLoss: 0.560601 averageDLoss 0.702978849411 dLossOfReal: 0.559947 dLossOfFake: 0.846011 Time Elapsed: 0:05:24\n",
      "Iteration: 51 gLoss: 0.560762 averageDLoss 0.703344702721 dLossOfReal: 0.560895 dLossOfFake: 0.845794 Time Elapsed: 0:05:30\n",
      "Iteration: 52 gLoss: 0.560923 averageDLoss 0.703095018864 dLossOfReal: 0.560608 dLossOfFake: 0.845582 Time Elapsed: 0:05:37\n",
      "Iteration: 53 gLoss: 0.561084 averageDLoss 0.702589869499 dLossOfReal: 0.559814 dLossOfFake: 0.845366 Time Elapsed: 0:05:43\n",
      "Iteration: 54 gLoss: 0.561245 averageDLoss 0.703167915344 dLossOfReal: 0.56118 dLossOfFake: 0.845155 Time Elapsed: 0:05:50\n",
      "Iteration: 55 gLoss: 0.561405 averageDLoss 0.703584015369 dLossOfReal: 0.562225 dLossOfFake: 0.844943 Time Elapsed: 0:05:56\n",
      "Iteration: 56 gLoss: 0.561566 averageDLoss 0.702989935875 dLossOfReal: 0.561251 dLossOfFake: 0.844729 Time Elapsed: 0:06:02\n",
      "Iteration: 57 gLoss: 0.561723 averageDLoss 0.702509880066 dLossOfReal: 0.560502 dLossOfFake: 0.844518 Time Elapsed: 0:06:09\n",
      "Iteration: 58 gLoss: 0.561884 averageDLoss 0.703044056892 dLossOfReal: 0.561782 dLossOfFake: 0.844306 Time Elapsed: 0:06:15\n",
      "Iteration: 59 gLoss: 0.562042 averageDLoss 0.7021920681 dLossOfReal: 0.560289 dLossOfFake: 0.844095 Time Elapsed: 0:06:22\n",
      "Iteration: 60 gLoss: 0.562201 averageDLoss 0.702678978443 dLossOfReal: 0.561475 dLossOfFake: 0.843883 Time Elapsed: 0:06:29\n",
      "Iteration: 61 gLoss: 0.562359 averageDLoss 0.702263116837 dLossOfReal: 0.560852 dLossOfFake: 0.843674 Time Elapsed: 0:06:35\n",
      "Iteration: 62 gLoss: 0.562516 averageDLoss 0.702703952789 dLossOfReal: 0.56194 dLossOfFake: 0.843468 Time Elapsed: 0:06:42\n",
      "Iteration: 63 gLoss: 0.562674 averageDLoss 0.702615320683 dLossOfReal: 0.561971 dLossOfFake: 0.84326 Time Elapsed: 0:06:48\n",
      "Iteration: 64 gLoss: 0.56283 averageDLoss 0.702971577644 dLossOfReal: 0.56289 dLossOfFake: 0.843053 Time Elapsed: 0:06:55\n",
      "Iteration: 65 gLoss: 0.562982 averageDLoss 0.703819870949 dLossOfReal: 0.564792 dLossOfFake: 0.842847 Time Elapsed: 0:07:01\n",
      "Iteration: 66 gLoss: 0.563141 averageDLoss 0.702529847622 dLossOfReal: 0.562419 dLossOfFake: 0.842641 Time Elapsed: 0:07:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 67 gLoss: 0.563293 averageDLoss 0.703399896622 dLossOfReal: 0.564363 dLossOfFake: 0.842437 Time Elapsed: 0:07:15\n",
      "Iteration: 68 gLoss: 0.563449 averageDLoss 0.70305287838 dLossOfReal: 0.563874 dLossOfFake: 0.842231 Time Elapsed: 0:07:21\n",
      "Iteration: 69 gLoss: 0.563604 averageDLoss 0.702597618103 dLossOfReal: 0.563169 dLossOfFake: 0.842026 Time Elapsed: 0:07:27\n",
      "Iteration: 70 gLoss: 0.563763 averageDLoss 0.702304065228 dLossOfReal: 0.56279 dLossOfFake: 0.841818 Time Elapsed: 0:07:34\n",
      "Iteration: 71 gLoss: 0.563915 averageDLoss 0.702147245407 dLossOfReal: 0.56268 dLossOfFake: 0.841614 Time Elapsed: 0:07:40\n",
      "Iteration: 72 gLoss: 0.564068 averageDLoss 0.702714264393 dLossOfReal: 0.564014 dLossOfFake: 0.841415 Time Elapsed: 0:07:47\n",
      "Iteration: 73 gLoss: 0.564221 averageDLoss 0.702876806259 dLossOfReal: 0.564541 dLossOfFake: 0.841213 Time Elapsed: 0:07:53\n",
      "Iteration: 74 gLoss: 0.564372 averageDLoss 0.70212829113 dLossOfReal: 0.563242 dLossOfFake: 0.841015 Time Elapsed: 0:08:00\n",
      "Iteration: 75 gLoss: 0.564526 averageDLoss 0.703154861927 dLossOfReal: 0.565499 dLossOfFake: 0.840811 Time Elapsed: 0:08:06\n",
      "Iteration: 76 gLoss: 0.564679 averageDLoss 0.702468276024 dLossOfReal: 0.564327 dLossOfFake: 0.840609 Time Elapsed: 0:08:12\n",
      "Iteration: 77 gLoss: 0.56483 averageDLoss 0.702172577381 dLossOfReal: 0.563938 dLossOfFake: 0.840407 Time Elapsed: 0:08:19\n",
      "Iteration: 78 gLoss: 0.564981 averageDLoss 0.702992320061 dLossOfReal: 0.565773 dLossOfFake: 0.840211 Time Elapsed: 0:08:25\n",
      "Iteration: 79 gLoss: 0.565132 averageDLoss 0.702738523483 dLossOfReal: 0.565462 dLossOfFake: 0.840015 Time Elapsed: 0:08:32\n",
      "Iteration: 80 gLoss: 0.565283 averageDLoss 0.702243387699 dLossOfReal: 0.564671 dLossOfFake: 0.839815 Time Elapsed: 0:08:38\n",
      "Iteration: 81 gLoss: 0.565431 averageDLoss 0.70209133625 dLossOfReal: 0.564565 dLossOfFake: 0.839618 Time Elapsed: 0:08:45\n",
      "Iteration: 82 gLoss: 0.565579 averageDLoss 0.702135443687 dLossOfReal: 0.564848 dLossOfFake: 0.839423 Time Elapsed: 0:08:51\n",
      "Iteration: 83 gLoss: 0.565728 averageDLoss 0.701403021812 dLossOfReal: 0.563576 dLossOfFake: 0.83923 Time Elapsed: 0:08:58\n",
      "Iteration: 84 gLoss: 0.565875 averageDLoss 0.701846659184 dLossOfReal: 0.56466 dLossOfFake: 0.839034 Time Elapsed: 0:09:04\n",
      "Iteration: 85 gLoss: 0.566023 averageDLoss 0.702196002007 dLossOfReal: 0.565552 dLossOfFake: 0.83884 Time Elapsed: 0:09:11\n",
      "Iteration: 86 gLoss: 0.566171 averageDLoss 0.701710999012 dLossOfReal: 0.564774 dLossOfFake: 0.838648 Time Elapsed: 0:09:17\n",
      "Iteration: 87 gLoss: 0.566317 averageDLoss 0.702585816383 dLossOfReal: 0.566716 dLossOfFake: 0.838455 Time Elapsed: 0:09:24\n",
      "Iteration: 88 gLoss: 0.566461 averageDLoss 0.70158457756 dLossOfReal: 0.564905 dLossOfFake: 0.838264 Time Elapsed: 0:09:30\n",
      "Iteration: 89 gLoss: 0.566606 averageDLoss 0.702393889427 dLossOfReal: 0.566712 dLossOfFake: 0.838075 Time Elapsed: 0:09:37\n",
      "Iteration: 90 gLoss: 0.566754 averageDLoss 0.701550900936 dLossOfReal: 0.565222 dLossOfFake: 0.83788 Time Elapsed: 0:09:43\n",
      "Iteration: 91 gLoss: 0.5669 averageDLoss 0.70187330246 dLossOfReal: 0.566055 dLossOfFake: 0.837691 Time Elapsed: 0:09:50\n",
      "Iteration: 92 gLoss: 0.567045 averageDLoss 0.702249646187 dLossOfReal: 0.567 dLossOfFake: 0.837499 Time Elapsed: 0:09:56\n",
      "Iteration: 93 gLoss: 0.56719 averageDLoss 0.702072322369 dLossOfReal: 0.566835 dLossOfFake: 0.83731 Time Elapsed: 0:10:03\n",
      "Iteration: 94 gLoss: 0.567336 averageDLoss 0.702234148979 dLossOfReal: 0.56735 dLossOfFake: 0.837118 Time Elapsed: 0:10:09\n",
      "Iteration: 95 gLoss: 0.567479 averageDLoss 0.701824784279 dLossOfReal: 0.566719 dLossOfFake: 0.83693 Time Elapsed: 0:10:16\n",
      "Iteration: 96 gLoss: 0.567624 averageDLoss 0.701713681221 dLossOfReal: 0.566685 dLossOfFake: 0.836742 Time Elapsed: 0:10:22\n",
      "Iteration: 97 gLoss: 0.567767 averageDLoss 0.701821684837 dLossOfReal: 0.56709 dLossOfFake: 0.836553 Time Elapsed: 0:10:29\n",
      "Iteration: 98 gLoss: 0.567908 averageDLoss 0.700483679771 dLossOfReal: 0.564599 dLossOfFake: 0.836369 Time Elapsed: 0:10:35\n",
      "Iteration: 99 gLoss: 0.568048 averageDLoss 0.70157456398 dLossOfReal: 0.566967 dLossOfFake: 0.836183 Time Elapsed: 0:10:42\n",
      "Iteration: 100 gLoss: 0.568195 averageDLoss 0.700191140175 dLossOfReal: 0.564385 dLossOfFake: 0.835997 Time Elapsed: 0:10:48\n",
      "Iteration: 101 gLoss: 0.568335 averageDLoss 0.700855255127 dLossOfReal: 0.565898 dLossOfFake: 0.835812 Time Elapsed: 0:10:55\n",
      "Iteration: 102 gLoss: 0.568475 averageDLoss 0.700612068176 dLossOfReal: 0.565597 dLossOfFake: 0.835627 Time Elapsed: 0:11:01\n",
      "Iteration: 103 gLoss: 0.568617 averageDLoss 0.701681375504 dLossOfReal: 0.567921 dLossOfFake: 0.835442 Time Elapsed: 0:11:08\n",
      "Iteration: 104 gLoss: 0.568758 averageDLoss 0.701089203358 dLossOfReal: 0.56692 dLossOfFake: 0.835258 Time Elapsed: 0:11:15\n",
      "Iteration: 105 gLoss: 0.568897 averageDLoss 0.701877474785 dLossOfReal: 0.568681 dLossOfFake: 0.835074 Time Elapsed: 0:11:22\n",
      "Iteration: 106 gLoss: 0.569038 averageDLoss 0.701299250126 dLossOfReal: 0.567707 dLossOfFake: 0.834892 Time Elapsed: 0:11:28\n",
      "Iteration: 107 gLoss: 0.56918 averageDLoss 0.701361477375 dLossOfReal: 0.568014 dLossOfFake: 0.834709 Time Elapsed: 0:11:35\n",
      "Iteration: 108 gLoss: 0.569321 averageDLoss 0.701204419136 dLossOfReal: 0.567883 dLossOfFake: 0.834525 Time Elapsed: 0:11:41\n",
      "Iteration: 109 gLoss: 0.569461 averageDLoss 0.702039718628 dLossOfReal: 0.569738 dLossOfFake: 0.834341 Time Elapsed: 0:11:48\n",
      "Iteration: 110 gLoss: 0.569599 averageDLoss 0.701833248138 dLossOfReal: 0.569506 dLossOfFake: 0.83416 Time Elapsed: 0:11:55\n",
      "Iteration: 111 gLoss: 0.569737 averageDLoss 0.701513707638 dLossOfReal: 0.569043 dLossOfFake: 0.833984 Time Elapsed: 0:12:01\n",
      "Iteration: 112 gLoss: 0.569872 averageDLoss 0.701581835747 dLossOfReal: 0.569362 dLossOfFake: 0.833802 Time Elapsed: 0:12:08\n",
      "Iteration: 113 gLoss: 0.57001 averageDLoss 0.700576901436 dLossOfReal: 0.567527 dLossOfFake: 0.833626 Time Elapsed: 0:12:15\n",
      "Iteration: 114 gLoss: 0.570147 averageDLoss 0.701266944408 dLossOfReal: 0.569083 dLossOfFake: 0.833451 Time Elapsed: 0:12:21\n",
      "Iteration: 115 gLoss: 0.570279 averageDLoss 0.701813697815 dLossOfReal: 0.570352 dLossOfFake: 0.833275 Time Elapsed: 0:12:28\n",
      "Iteration: 116 gLoss: 0.570417 averageDLoss 0.701207399368 dLossOfReal: 0.569321 dLossOfFake: 0.833093 Time Elapsed: 0:12:34\n",
      "Iteration: 117 gLoss: 0.570554 averageDLoss 0.701921343803 dLossOfReal: 0.570925 dLossOfFake: 0.832918 Time Elapsed: 0:12:41\n",
      "Iteration: 118 gLoss: 0.570691 averageDLoss 0.70120960474 dLossOfReal: 0.569678 dLossOfFake: 0.832741 Time Elapsed: 0:12:48\n",
      "Iteration: 119 gLoss: 0.570827 averageDLoss 0.701068937778 dLossOfReal: 0.569572 dLossOfFake: 0.832566 Time Elapsed: 0:12:54\n",
      "Iteration: 120 gLoss: 0.57096 averageDLoss 0.701562643051 dLossOfReal: 0.570736 dLossOfFake: 0.83239 Time Elapsed: 0:13:01\n",
      "Iteration: 121 gLoss: 0.571095 averageDLoss 0.701397895813 dLossOfReal: 0.57058 dLossOfFake: 0.832216 Time Elapsed: 0:13:07\n",
      "Iteration: 122 gLoss: 0.571229 averageDLoss 0.701224803925 dLossOfReal: 0.570405 dLossOfFake: 0.832044 Time Elapsed: 0:13:14\n",
      "Iteration: 123 gLoss: 0.571361 averageDLoss 0.700823426247 dLossOfReal: 0.569775 dLossOfFake: 0.831872 Time Elapsed: 0:13:21\n",
      "Iteration: 124 gLoss: 0.571495 averageDLoss 0.701326489449 dLossOfReal: 0.570956 dLossOfFake: 0.831697 Time Elapsed: 0:13:28\n",
      "Iteration: 125 gLoss: 0.571626 averageDLoss 0.701269626617 dLossOfReal: 0.571012 dLossOfFake: 0.831527 Time Elapsed: 0:13:34\n",
      "Iteration: 126 gLoss: 0.571761 averageDLoss 0.701030611992 dLossOfReal: 0.570709 dLossOfFake: 0.831353 Time Elapsed: 0:13:41\n",
      "Iteration: 127 gLoss: 0.571893 averageDLoss 0.700981736183 dLossOfReal: 0.570781 dLossOfFake: 0.831183 Time Elapsed: 0:13:48\n",
      "Iteration: 128 gLoss: 0.572025 averageDLoss 0.700944423676 dLossOfReal: 0.57088 dLossOfFake: 0.831009 Time Elapsed: 0:13:54\n",
      "Iteration: 129 gLoss: 0.572157 averageDLoss 0.700410842896 dLossOfReal: 0.569985 dLossOfFake: 0.830836 Time Elapsed: 0:14:01\n",
      "Iteration: 130 gLoss: 0.572286 averageDLoss 0.701720893383 dLossOfReal: 0.572775 dLossOfFake: 0.830667 Time Elapsed: 0:14:08\n",
      "Iteration: 131 gLoss: 0.572418 averageDLoss 0.701521754265 dLossOfReal: 0.572542 dLossOfFake: 0.830501 Time Elapsed: 0:14:14\n",
      "Iteration: 132 gLoss: 0.572547 averageDLoss 0.701222062111 dLossOfReal: 0.572111 dLossOfFake: 0.830333 Time Elapsed: 0:14:21\n",
      "Iteration: 133 gLoss: 0.572679 averageDLoss 0.700927078724 dLossOfReal: 0.571689 dLossOfFake: 0.830165 Time Elapsed: 0:14:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 134 gLoss: 0.572808 averageDLoss 0.700976490974 dLossOfReal: 0.571958 dLossOfFake: 0.829995 Time Elapsed: 0:14:34\n",
      "Iteration: 135 gLoss: 0.572937 averageDLoss 0.700274169445 dLossOfReal: 0.570721 dLossOfFake: 0.829827 Time Elapsed: 0:14:41\n",
      "Iteration: 136 gLoss: 0.573061 averageDLoss 0.700868487358 dLossOfReal: 0.572074 dLossOfFake: 0.829663 Time Elapsed: 0:14:48\n",
      "Iteration: 137 gLoss: 0.573193 averageDLoss 0.700959503651 dLossOfReal: 0.572422 dLossOfFake: 0.829497 Time Elapsed: 0:14:55\n",
      "Iteration: 138 gLoss: 0.573322 averageDLoss 0.701235175133 dLossOfReal: 0.573141 dLossOfFake: 0.829329 Time Elapsed: 0:15:01\n",
      "Iteration: 139 gLoss: 0.573452 averageDLoss 0.700718283653 dLossOfReal: 0.572271 dLossOfFake: 0.829165 Time Elapsed: 0:15:08\n",
      "Iteration: 140 gLoss: 0.573578 averageDLoss 0.699736237526 dLossOfReal: 0.570474 dLossOfFake: 0.828999 Time Elapsed: 0:15:15\n",
      "Iteration: 141 gLoss: 0.573706 averageDLoss 0.699930906296 dLossOfReal: 0.571028 dLossOfFake: 0.828833 Time Elapsed: 0:15:21\n",
      "Iteration: 142 gLoss: 0.573833 averageDLoss 0.700728654861 dLossOfReal: 0.572785 dLossOfFake: 0.828672 Time Elapsed: 0:15:28\n",
      "Iteration: 143 gLoss: 0.573958 averageDLoss 0.700144529343 dLossOfReal: 0.571779 dLossOfFake: 0.828511 Time Elapsed: 0:15:35\n",
      "Iteration: 144 gLoss: 0.574085 averageDLoss 0.700339078903 dLossOfReal: 0.572332 dLossOfFake: 0.828346 Time Elapsed: 0:15:41\n",
      "Iteration: 145 gLoss: 0.574211 averageDLoss 0.699847340584 dLossOfReal: 0.571511 dLossOfFake: 0.828184 Time Elapsed: 0:15:48\n",
      "Iteration: 146 gLoss: 0.574335 averageDLoss 0.700767278671 dLossOfReal: 0.573511 dLossOfFake: 0.828024 Time Elapsed: 0:15:55\n",
      "Iteration: 147 gLoss: 0.574459 averageDLoss 0.70066434145 dLossOfReal: 0.573465 dLossOfFake: 0.827864 Time Elapsed: 0:16:02\n",
      "Iteration: 148 gLoss: 0.574583 averageDLoss 0.699697911739 dLossOfReal: 0.571695 dLossOfFake: 0.827701 Time Elapsed: 0:16:08\n",
      "Iteration: 149 gLoss: 0.574709 averageDLoss 0.700399875641 dLossOfReal: 0.573258 dLossOfFake: 0.827542 Time Elapsed: 0:16:15\n",
      "Iteration: 150 gLoss: 0.574834 averageDLoss 0.700989067554 dLossOfReal: 0.574598 dLossOfFake: 0.82738 Time Elapsed: 0:16:22\n",
      "Iteration: 151 gLoss: 0.574957 averageDLoss 0.700169444084 dLossOfReal: 0.573117 dLossOfFake: 0.827222 Time Elapsed: 0:16:29\n",
      "Iteration: 152 gLoss: 0.575081 averageDLoss 0.700215756893 dLossOfReal: 0.573369 dLossOfFake: 0.827063 Time Elapsed: 0:16:36\n",
      "Iteration: 153 gLoss: 0.575205 averageDLoss 0.700341761112 dLossOfReal: 0.573781 dLossOfFake: 0.826902 Time Elapsed: 0:16:43\n",
      "Iteration: 154 gLoss: 0.575331 averageDLoss 0.70040512085 dLossOfReal: 0.574071 dLossOfFake: 0.82674 Time Elapsed: 0:16:49\n",
      "Iteration: 155 gLoss: 0.575451 averageDLoss 0.699654221535 dLossOfReal: 0.572723 dLossOfFake: 0.826586 Time Elapsed: 0:16:56\n",
      "Iteration: 156 gLoss: 0.575574 averageDLoss 0.699855148792 dLossOfReal: 0.573282 dLossOfFake: 0.826429 Time Elapsed: 0:17:03\n",
      "Iteration: 157 gLoss: 0.575697 averageDLoss 0.700232207775 dLossOfReal: 0.574193 dLossOfFake: 0.826272 Time Elapsed: 0:17:10\n",
      "Iteration: 158 gLoss: 0.575814 averageDLoss 0.70009636879 dLossOfReal: 0.574075 dLossOfFake: 0.826117 Time Elapsed: 0:17:17\n",
      "Iteration: 159 gLoss: 0.575938 averageDLoss 0.699640870094 dLossOfReal: 0.573323 dLossOfFake: 0.825958 Time Elapsed: 0:17:25\n",
      "Iteration: 160 gLoss: 0.576061 averageDLoss 0.699909448624 dLossOfReal: 0.574015 dLossOfFake: 0.825804 Time Elapsed: 0:17:32\n",
      "Iteration: 161 gLoss: 0.576181 averageDLoss 0.70034635067 dLossOfReal: 0.575043 dLossOfFake: 0.82565 Time Elapsed: 0:17:39\n",
      "Iteration: 162 gLoss: 0.5763 averageDLoss 0.699897527695 dLossOfReal: 0.574298 dLossOfFake: 0.825497 Time Elapsed: 0:17:46\n",
      "Iteration: 163 gLoss: 0.576426 averageDLoss 0.699843287468 dLossOfReal: 0.574346 dLossOfFake: 0.82534 Time Elapsed: 0:17:52\n",
      "Iteration: 164 gLoss: 0.576544 averageDLoss 0.699261784554 dLossOfReal: 0.573342 dLossOfFake: 0.825181 Time Elapsed: 0:17:59\n",
      "Iteration: 165 gLoss: 0.576666 averageDLoss 0.700891673565 dLossOfReal: 0.576755 dLossOfFake: 0.825028 Time Elapsed: 0:18:06\n",
      "Iteration: 166 gLoss: 0.576784 averageDLoss 0.699667811394 dLossOfReal: 0.574461 dLossOfFake: 0.824875 Time Elapsed: 0:18:13\n",
      "Iteration: 167 gLoss: 0.576902 averageDLoss 0.699823737144 dLossOfReal: 0.574928 dLossOfFake: 0.82472 Time Elapsed: 0:18:20\n",
      "Iteration: 168 gLoss: 0.57702 averageDLoss 0.699253678322 dLossOfReal: 0.573938 dLossOfFake: 0.824569 Time Elapsed: 0:18:27\n",
      "Iteration: 169 gLoss: 0.577138 averageDLoss 0.700589299202 dLossOfReal: 0.576756 dLossOfFake: 0.824423 Time Elapsed: 0:18:33\n",
      "Iteration: 170 gLoss: 0.577257 averageDLoss 0.699694275856 dLossOfReal: 0.575119 dLossOfFake: 0.82427 Time Elapsed: 0:18:40\n",
      "Iteration: 171 gLoss: 0.577374 averageDLoss 0.699215531349 dLossOfReal: 0.574312 dLossOfFake: 0.824119 Time Elapsed: 0:18:48\n",
      "Iteration: 172 gLoss: 0.577492 averageDLoss 0.700388848782 dLossOfReal: 0.576809 dLossOfFake: 0.823968 Time Elapsed: 0:18:55\n",
      "Iteration: 173 gLoss: 0.577611 averageDLoss 0.699085950851 dLossOfReal: 0.574356 dLossOfFake: 0.823815 Time Elapsed: 0:19:02\n",
      "Iteration: 174 gLoss: 0.577727 averageDLoss 0.70035815239 dLossOfReal: 0.577046 dLossOfFake: 0.82367 Time Elapsed: 0:19:08\n",
      "Iteration: 175 gLoss: 0.577847 averageDLoss 0.699817895889 dLossOfReal: 0.576116 dLossOfFake: 0.823519 Time Elapsed: 0:19:15\n",
      "Iteration: 176 gLoss: 0.577962 averageDLoss 0.700113415718 dLossOfReal: 0.576857 dLossOfFake: 0.82337 Time Elapsed: 0:19:22\n",
      "Iteration: 177 gLoss: 0.578076 averageDLoss 0.698698282242 dLossOfReal: 0.574175 dLossOfFake: 0.823221 Time Elapsed: 0:19:29\n",
      "Iteration: 178 gLoss: 0.578192 averageDLoss 0.699880838394 dLossOfReal: 0.576688 dLossOfFake: 0.823073 Time Elapsed: 0:19:36\n",
      "Iteration: 179 gLoss: 0.578309 averageDLoss 0.699373662472 dLossOfReal: 0.57582 dLossOfFake: 0.822927 Time Elapsed: 0:19:43\n",
      "Iteration: 180 gLoss: 0.578421 averageDLoss 0.699566185474 dLossOfReal: 0.576354 dLossOfFake: 0.822779 Time Elapsed: 0:19:50\n",
      "Iteration: 181 gLoss: 0.578537 averageDLoss 0.699679553509 dLossOfReal: 0.576727 dLossOfFake: 0.822632 Time Elapsed: 0:19:57\n",
      "Iteration: 182 gLoss: 0.578652 averageDLoss 0.699488699436 dLossOfReal: 0.576493 dLossOfFake: 0.822484 Time Elapsed: 0:20:04\n",
      "Iteration: 183 gLoss: 0.578764 averageDLoss 0.699596405029 dLossOfReal: 0.576854 dLossOfFake: 0.822339 Time Elapsed: 0:20:11\n",
      "Iteration: 184 gLoss: 0.57888 averageDLoss 0.699561476707 dLossOfReal: 0.576927 dLossOfFake: 0.822196 Time Elapsed: 0:20:18\n",
      "Iteration: 185 gLoss: 0.578992 averageDLoss 0.69928586483 dLossOfReal: 0.57652 dLossOfFake: 0.822052 Time Elapsed: 0:20:24\n",
      "Iteration: 186 gLoss: 0.579103 averageDLoss 0.699467301369 dLossOfReal: 0.577023 dLossOfFake: 0.821911 Time Elapsed: 0:20:31\n",
      "Iteration: 187 gLoss: 0.57922 averageDLoss 0.699004650116 dLossOfReal: 0.576245 dLossOfFake: 0.821764 Time Elapsed: 0:20:38\n",
      "Iteration: 188 gLoss: 0.579332 averageDLoss 0.699563205242 dLossOfReal: 0.57751 dLossOfFake: 0.821617 Time Elapsed: 0:20:45\n",
      "Iteration: 189 gLoss: 0.579444 averageDLoss 0.699334144592 dLossOfReal: 0.577193 dLossOfFake: 0.821476 Time Elapsed: 0:20:52\n",
      "Iteration: 190 gLoss: 0.579558 averageDLoss 0.698910832405 dLossOfReal: 0.576492 dLossOfFake: 0.821329 Time Elapsed: 0:20:59\n",
      "Iteration: 191 gLoss: 0.579671 averageDLoss 0.699598252773 dLossOfReal: 0.578009 dLossOfFake: 0.821187 Time Elapsed: 0:21:06\n",
      "Iteration: 192 gLoss: 0.579782 averageDLoss 0.699528753757 dLossOfReal: 0.57801 dLossOfFake: 0.821047 Time Elapsed: 0:21:13\n",
      "Iteration: 193 gLoss: 0.579893 averageDLoss 0.698953151703 dLossOfReal: 0.577004 dLossOfFake: 0.820902 Time Elapsed: 0:21:20\n",
      "Iteration: 194 gLoss: 0.580006 averageDLoss 0.699489355087 dLossOfReal: 0.578218 dLossOfFake: 0.820761 Time Elapsed: 0:21:27\n",
      "Iteration: 195 gLoss: 0.580115 averageDLoss 0.699183821678 dLossOfReal: 0.577747 dLossOfFake: 0.820621 Time Elapsed: 0:21:34\n",
      "Iteration: 196 gLoss: 0.580226 averageDLoss 0.698953866959 dLossOfReal: 0.577428 dLossOfFake: 0.82048 Time Elapsed: 0:21:41\n",
      "Iteration: 197 gLoss: 0.580336 averageDLoss 0.699682831764 dLossOfReal: 0.579026 dLossOfFake: 0.82034 Time Elapsed: 0:21:48\n",
      "Iteration: 198 gLoss: 0.580447 averageDLoss 0.69943010807 dLossOfReal: 0.57866 dLossOfFake: 0.8202 Time Elapsed: 0:21:55\n",
      "Iteration: 199 gLoss: 0.580557 averageDLoss 0.699155390263 dLossOfReal: 0.57825 dLossOfFake: 0.820061 Time Elapsed: 0:22:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 200 gLoss: 0.580667 averageDLoss 0.699369311333 dLossOfReal: 0.578817 dLossOfFake: 0.819922 Time Elapsed: 0:22:09\n",
      "Iteration: 201 gLoss: 0.580776 averageDLoss 0.699511945248 dLossOfReal: 0.579242 dLossOfFake: 0.819782 Time Elapsed: 0:22:16\n",
      "Iteration: 202 gLoss: 0.580887 averageDLoss 0.699481964111 dLossOfReal: 0.57932 dLossOfFake: 0.819643 Time Elapsed: 0:22:23\n",
      "Iteration: 203 gLoss: 0.580996 averageDLoss 0.699162065983 dLossOfReal: 0.578821 dLossOfFake: 0.819503 Time Elapsed: 0:22:30\n",
      "Iteration: 204 gLoss: 0.581104 averageDLoss 0.699328839779 dLossOfReal: 0.579293 dLossOfFake: 0.819365 Time Elapsed: 0:22:37\n",
      "Iteration: 205 gLoss: 0.581212 averageDLoss 0.698702573776 dLossOfReal: 0.578176 dLossOfFake: 0.819229 Time Elapsed: 0:22:44\n",
      "Iteration: 206 gLoss: 0.581319 averageDLoss 0.699577450752 dLossOfReal: 0.580063 dLossOfFake: 0.819092 Time Elapsed: 0:22:51\n",
      "Iteration: 207 gLoss: 0.581429 averageDLoss 0.698970198631 dLossOfReal: 0.578984 dLossOfFake: 0.818956 Time Elapsed: 0:22:58\n",
      "Iteration: 208 gLoss: 0.581534 averageDLoss 0.699591755867 dLossOfReal: 0.580366 dLossOfFake: 0.818818 Time Elapsed: 0:23:05\n",
      "Iteration: 209 gLoss: 0.581641 averageDLoss 0.699148118496 dLossOfReal: 0.579613 dLossOfFake: 0.818683 Time Elapsed: 0:23:12\n",
      "Iteration: 210 gLoss: 0.581749 averageDLoss 0.699491739273 dLossOfReal: 0.580434 dLossOfFake: 0.818549 Time Elapsed: 0:23:19\n",
      "Iteration: 211 gLoss: 0.581857 averageDLoss 0.699151873589 dLossOfReal: 0.579893 dLossOfFake: 0.818411 Time Elapsed: 0:23:26\n",
      "Iteration: 212 gLoss: 0.581964 averageDLoss 0.698994755745 dLossOfReal: 0.579716 dLossOfFake: 0.818273 Time Elapsed: 0:23:33\n",
      "Iteration: 213 gLoss: 0.582071 averageDLoss 0.69881016016 dLossOfReal: 0.57948 dLossOfFake: 0.818141 Time Elapsed: 0:23:40\n",
      "Iteration: 214 gLoss: 0.582173 averageDLoss 0.699001371861 dLossOfReal: 0.579994 dLossOfFake: 0.818008 Time Elapsed: 0:23:47\n",
      "Iteration: 215 gLoss: 0.582284 averageDLoss 0.69934284687 dLossOfReal: 0.580812 dLossOfFake: 0.817874 Time Elapsed: 0:23:54\n",
      "Iteration: 216 gLoss: 0.582387 averageDLoss 0.699062466621 dLossOfReal: 0.580384 dLossOfFake: 0.817741 Time Elapsed: 0:24:01\n",
      "Iteration: 217 gLoss: 0.582492 averageDLoss 0.698982179165 dLossOfReal: 0.580356 dLossOfFake: 0.817608 Time Elapsed: 0:24:08\n",
      "Iteration: 218 gLoss: 0.582596 averageDLoss 0.698408842087 dLossOfReal: 0.579346 dLossOfFake: 0.817472 Time Elapsed: 0:24:15\n",
      "Iteration: 219 gLoss: 0.582703 averageDLoss 0.698611497879 dLossOfReal: 0.579885 dLossOfFake: 0.817338 Time Elapsed: 0:24:22\n",
      "Iteration: 220 gLoss: 0.582805 averageDLoss 0.69800901413 dLossOfReal: 0.578806 dLossOfFake: 0.817212 Time Elapsed: 0:24:29\n",
      "Iteration: 221 gLoss: 0.582908 averageDLoss 0.698809504509 dLossOfReal: 0.580538 dLossOfFake: 0.817081 Time Elapsed: 0:24:36\n",
      "Iteration: 222 gLoss: 0.583013 averageDLoss 0.698983430862 dLossOfReal: 0.581018 dLossOfFake: 0.816949 Time Elapsed: 0:24:43\n",
      "Iteration: 223 gLoss: 0.583117 averageDLoss 0.698755860329 dLossOfReal: 0.580694 dLossOfFake: 0.816818 Time Elapsed: 0:24:50\n",
      "Iteration: 224 gLoss: 0.583222 averageDLoss 0.699306845665 dLossOfReal: 0.581928 dLossOfFake: 0.816686 Time Elapsed: 0:24:57\n",
      "Iteration: 225 gLoss: 0.583324 averageDLoss 0.698839902878 dLossOfReal: 0.581128 dLossOfFake: 0.816552 Time Elapsed: 0:25:04\n",
      "Iteration: 226 gLoss: 0.583427 averageDLoss 0.698775589466 dLossOfReal: 0.581127 dLossOfFake: 0.816425 Time Elapsed: 0:25:12\n",
      "Iteration: 227 gLoss: 0.583531 averageDLoss 0.698881268501 dLossOfReal: 0.58147 dLossOfFake: 0.816292 Time Elapsed: 0:25:19\n",
      "Iteration: 228 gLoss: 0.583634 averageDLoss 0.698678851128 dLossOfReal: 0.581193 dLossOfFake: 0.816165 Time Elapsed: 0:25:26\n",
      "Iteration: 229 gLoss: 0.583734 averageDLoss 0.698075532913 dLossOfReal: 0.580112 dLossOfFake: 0.816039 Time Elapsed: 0:25:33\n",
      "Iteration: 230 gLoss: 0.583834 averageDLoss 0.69888907671 dLossOfReal: 0.581868 dLossOfFake: 0.815911 Time Elapsed: 0:25:40\n",
      "Iteration: 231 gLoss: 0.583936 averageDLoss 0.698390841484 dLossOfReal: 0.580999 dLossOfFake: 0.815783 Time Elapsed: 0:25:47\n",
      "Iteration: 232 gLoss: 0.584037 averageDLoss 0.698705673218 dLossOfReal: 0.581756 dLossOfFake: 0.815655 Time Elapsed: 0:25:54\n",
      "Iteration: 233 gLoss: 0.584134 averageDLoss 0.69877409935 dLossOfReal: 0.582017 dLossOfFake: 0.815531 Time Elapsed: 0:26:01\n",
      "Iteration: 234 gLoss: 0.584239 averageDLoss 0.698320925236 dLossOfReal: 0.58124 dLossOfFake: 0.815402 Time Elapsed: 0:26:08\n",
      "Iteration: 235 gLoss: 0.584338 averageDLoss 0.698522090912 dLossOfReal: 0.581771 dLossOfFake: 0.815274 Time Elapsed: 0:26:16\n",
      "Iteration: 236 gLoss: 0.584439 averageDLoss 0.699539542198 dLossOfReal: 0.583931 dLossOfFake: 0.815148 Time Elapsed: 0:26:23\n",
      "Iteration: 237 gLoss: 0.58454 averageDLoss 0.699157834053 dLossOfReal: 0.583297 dLossOfFake: 0.815019 Time Elapsed: 0:26:30\n",
      "Iteration: 238 gLoss: 0.584639 averageDLoss 0.698969960213 dLossOfReal: 0.583046 dLossOfFake: 0.814894 Time Elapsed: 0:26:37\n",
      "Iteration: 239 gLoss: 0.584742 averageDLoss 0.698512077332 dLossOfReal: 0.582255 dLossOfFake: 0.814769 Time Elapsed: 0:26:44\n",
      "Iteration: 240 gLoss: 0.584838 averageDLoss 0.698283970356 dLossOfReal: 0.581926 dLossOfFake: 0.814642 Time Elapsed: 0:26:51\n",
      "Iteration: 241 gLoss: 0.584938 averageDLoss 0.698345780373 dLossOfReal: 0.582173 dLossOfFake: 0.814519 Time Elapsed: 0:26:58\n",
      "Iteration: 242 gLoss: 0.585037 averageDLoss 0.698586821556 dLossOfReal: 0.582778 dLossOfFake: 0.814396 Time Elapsed: 0:27:06\n",
      "Iteration: 243 gLoss: 0.585136 averageDLoss 0.698057472706 dLossOfReal: 0.581844 dLossOfFake: 0.814271 Time Elapsed: 0:27:13\n",
      "Iteration: 244 gLoss: 0.585236 averageDLoss 0.698102116585 dLossOfReal: 0.582058 dLossOfFake: 0.814147 Time Elapsed: 0:27:20\n",
      "Iteration: 245 gLoss: 0.585336 averageDLoss 0.698317170143 dLossOfReal: 0.582613 dLossOfFake: 0.814022 Time Elapsed: 0:27:27\n",
      "Iteration: 246 gLoss: 0.585435 averageDLoss 0.698531985283 dLossOfReal: 0.583168 dLossOfFake: 0.813896 Time Elapsed: 0:27:34\n",
      "Iteration: 247 gLoss: 0.585532 averageDLoss 0.698085784912 dLossOfReal: 0.582399 dLossOfFake: 0.813772 Time Elapsed: 0:27:42\n",
      "Iteration: 248 gLoss: 0.585627 averageDLoss 0.697863519192 dLossOfReal: 0.582071 dLossOfFake: 0.813656 Time Elapsed: 0:27:49\n",
      "Iteration: 249 gLoss: 0.585723 averageDLoss 0.698087930679 dLossOfReal: 0.582643 dLossOfFake: 0.813533 Time Elapsed: 0:27:56\n",
      "Iteration: 250 gLoss: 0.585819 averageDLoss 0.697441339493 dLossOfReal: 0.58147 dLossOfFake: 0.813412 Time Elapsed: 0:28:03\n",
      "Iteration: 251 gLoss: 0.585919 averageDLoss 0.698471903801 dLossOfReal: 0.583656 dLossOfFake: 0.813287 Time Elapsed: 0:28:10\n",
      "Iteration: 252 gLoss: 0.586013 averageDLoss 0.698178291321 dLossOfReal: 0.58319 dLossOfFake: 0.813167 Time Elapsed: 0:28:17\n",
      "Iteration: 253 gLoss: 0.586111 averageDLoss 0.697937011719 dLossOfReal: 0.582828 dLossOfFake: 0.813046 Time Elapsed: 0:28:25\n",
      "Iteration: 254 gLoss: 0.586207 averageDLoss 0.698286414146 dLossOfReal: 0.583648 dLossOfFake: 0.812925 Time Elapsed: 0:28:32\n",
      "Iteration: 255 gLoss: 0.586303 averageDLoss 0.698915064335 dLossOfReal: 0.585025 dLossOfFake: 0.812806 Time Elapsed: 0:28:39\n",
      "Iteration: 256 gLoss: 0.586396 averageDLoss 0.697806119919 dLossOfReal: 0.582927 dLossOfFake: 0.812685 Time Elapsed: 0:28:46\n",
      "Iteration: 257 gLoss: 0.586495 averageDLoss 0.69740986824 dLossOfReal: 0.582255 dLossOfFake: 0.812564 Time Elapsed: 0:28:53\n",
      "Iteration: 258 gLoss: 0.586588 averageDLoss 0.698265433311 dLossOfReal: 0.584083 dLossOfFake: 0.812448 Time Elapsed: 0:29:00\n",
      "Iteration: 259 gLoss: 0.586683 averageDLoss 0.698431253433 dLossOfReal: 0.584533 dLossOfFake: 0.812329 Time Elapsed: 0:29:08\n",
      "Iteration: 260 gLoss: 0.586778 averageDLoss 0.698562145233 dLossOfReal: 0.584914 dLossOfFake: 0.812211 Time Elapsed: 0:29:15\n",
      "Iteration: 261 gLoss: 0.58687 averageDLoss 0.697962462902 dLossOfReal: 0.583833 dLossOfFake: 0.812092 Time Elapsed: 0:29:22\n",
      "Iteration: 262 gLoss: 0.586966 averageDLoss 0.697787761688 dLossOfReal: 0.583603 dLossOfFake: 0.811972 Time Elapsed: 0:29:29\n",
      "Iteration: 263 gLoss: 0.58706 averageDLoss 0.698287665844 dLossOfReal: 0.584721 dLossOfFake: 0.811854 Time Elapsed: 0:29:37\n",
      "Iteration: 264 gLoss: 0.587156 averageDLoss 0.698536455631 dLossOfReal: 0.585336 dLossOfFake: 0.811737 Time Elapsed: 0:29:44\n",
      "Iteration: 265 gLoss: 0.587247 averageDLoss 0.697951555252 dLossOfReal: 0.584286 dLossOfFake: 0.811617 Time Elapsed: 0:29:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 266 gLoss: 0.587341 averageDLoss 0.698195397854 dLossOfReal: 0.584886 dLossOfFake: 0.811504 Time Elapsed: 0:29:58\n",
      "Iteration: 267 gLoss: 0.587434 averageDLoss 0.697487592697 dLossOfReal: 0.583588 dLossOfFake: 0.811387 Time Elapsed: 0:30:05\n",
      "Iteration: 268 gLoss: 0.587527 averageDLoss 0.698458313942 dLossOfReal: 0.585646 dLossOfFake: 0.811271 Time Elapsed: 0:30:13\n",
      "Iteration: 269 gLoss: 0.58762 averageDLoss 0.697814166546 dLossOfReal: 0.584473 dLossOfFake: 0.811155 Time Elapsed: 0:30:20\n",
      "Iteration: 270 gLoss: 0.587715 averageDLoss 0.697291493416 dLossOfReal: 0.583546 dLossOfFake: 0.811037 Time Elapsed: 0:30:28\n",
      "Iteration: 271 gLoss: 0.587805 averageDLoss 0.697968482971 dLossOfReal: 0.585013 dLossOfFake: 0.810924 Time Elapsed: 0:30:35\n",
      "Iteration: 272 gLoss: 0.587897 averageDLoss 0.698017001152 dLossOfReal: 0.585226 dLossOfFake: 0.810808 Time Elapsed: 0:30:42\n",
      "Iteration: 273 gLoss: 0.587988 averageDLoss 0.698141813278 dLossOfReal: 0.585588 dLossOfFake: 0.810696 Time Elapsed: 0:30:50\n",
      "Iteration: 274 gLoss: 0.58808 averageDLoss 0.697219967842 dLossOfReal: 0.583859 dLossOfFake: 0.810581 Time Elapsed: 0:30:57\n",
      "Iteration: 275 gLoss: 0.58817 averageDLoss 0.697846591473 dLossOfReal: 0.585226 dLossOfFake: 0.810467 Time Elapsed: 0:31:04\n",
      "Iteration: 276 gLoss: 0.588259 averageDLoss 0.697564721107 dLossOfReal: 0.584774 dLossOfFake: 0.810355 Time Elapsed: 0:31:11\n",
      "Iteration: 277 gLoss: 0.588354 averageDLoss 0.698196411133 dLossOfReal: 0.586156 dLossOfFake: 0.810236 Time Elapsed: 0:31:19\n",
      "Iteration: 278 gLoss: 0.588444 averageDLoss 0.697277903557 dLossOfReal: 0.584431 dLossOfFake: 0.810125 Time Elapsed: 0:31:26\n",
      "Iteration: 279 gLoss: 0.588533 averageDLoss 0.697530865669 dLossOfReal: 0.585049 dLossOfFake: 0.810012 Time Elapsed: 0:31:34\n",
      "Iteration: 280 gLoss: 0.588623 averageDLoss 0.698049783707 dLossOfReal: 0.5862 dLossOfFake: 0.8099 Time Elapsed: 0:31:41\n",
      "Iteration: 281 gLoss: 0.588711 averageDLoss 0.69779074192 dLossOfReal: 0.58579 dLossOfFake: 0.809792 Time Elapsed: 0:31:48\n",
      "Iteration: 282 gLoss: 0.588803 averageDLoss 0.697718381882 dLossOfReal: 0.585757 dLossOfFake: 0.80968 Time Elapsed: 0:31:55\n",
      "Iteration: 283 gLoss: 0.588889 averageDLoss 0.69795447588 dLossOfReal: 0.586338 dLossOfFake: 0.809571 Time Elapsed: 0:32:03\n",
      "Iteration: 284 gLoss: 0.58898 averageDLoss 0.697358965874 dLossOfReal: 0.585262 dLossOfFake: 0.809456 Time Elapsed: 0:32:10\n",
      "Iteration: 285 gLoss: 0.589068 averageDLoss 0.697555065155 dLossOfReal: 0.585766 dLossOfFake: 0.809344 Time Elapsed: 0:32:17\n",
      "Iteration: 286 gLoss: 0.589159 averageDLoss 0.698036909103 dLossOfReal: 0.58684 dLossOfFake: 0.809234 Time Elapsed: 0:32:25\n",
      "Iteration: 287 gLoss: 0.589249 averageDLoss 0.697075128555 dLossOfReal: 0.585029 dLossOfFake: 0.809121 Time Elapsed: 0:32:32\n",
      "Iteration: 288 gLoss: 0.589338 averageDLoss 0.697407960892 dLossOfReal: 0.585805 dLossOfFake: 0.809011 Time Elapsed: 0:32:39\n",
      "Iteration: 289 gLoss: 0.589425 averageDLoss 0.698178291321 dLossOfReal: 0.587455 dLossOfFake: 0.808902 Time Elapsed: 0:32:46\n",
      "Iteration: 290 gLoss: 0.589514 averageDLoss 0.696774125099 dLossOfReal: 0.584757 dLossOfFake: 0.808792 Time Elapsed: 0:32:54\n",
      "Iteration: 291 gLoss: 0.589603 averageDLoss 0.697085559368 dLossOfReal: 0.585488 dLossOfFake: 0.808683 Time Elapsed: 0:33:01\n",
      "Iteration: 292 gLoss: 0.58969 averageDLoss 0.697705864906 dLossOfReal: 0.58684 dLossOfFake: 0.808571 Time Elapsed: 0:33:08\n",
      "Iteration: 293 gLoss: 0.589777 averageDLoss 0.69763314724 dLossOfReal: 0.5868 dLossOfFake: 0.808466 Time Elapsed: 0:33:15\n",
      "Iteration: 294 gLoss: 0.589865 averageDLoss 0.697155296803 dLossOfReal: 0.585953 dLossOfFake: 0.808357 Time Elapsed: 0:33:23\n",
      "Iteration: 295 gLoss: 0.58995 averageDLoss 0.697624921799 dLossOfReal: 0.587 dLossOfFake: 0.80825 Time Elapsed: 0:33:30\n",
      "Iteration: 296 gLoss: 0.590037 averageDLoss 0.697918653488 dLossOfReal: 0.587695 dLossOfFake: 0.808142 Time Elapsed: 0:33:37\n",
      "Iteration: 297 gLoss: 0.590124 averageDLoss 0.697355747223 dLossOfReal: 0.586679 dLossOfFake: 0.808032 Time Elapsed: 0:33:45\n",
      "Iteration: 298 gLoss: 0.590211 averageDLoss 0.698278903961 dLossOfReal: 0.588634 dLossOfFake: 0.807924 Time Elapsed: 0:33:52\n",
      "Iteration: 299 gLoss: 0.590296 averageDLoss 0.697416782379 dLossOfReal: 0.587018 dLossOfFake: 0.807815 Time Elapsed: 0:33:59\n",
      "Iteration: 300 gLoss: 0.590384 averageDLoss 0.697198748589 dLossOfReal: 0.586691 dLossOfFake: 0.807707 Time Elapsed: 0:34:07\n",
      "Iteration: 301 gLoss: 0.59047 averageDLoss 0.697621464729 dLossOfReal: 0.58764 dLossOfFake: 0.807603 Time Elapsed: 0:34:14\n",
      "Iteration: 302 gLoss: 0.590558 averageDLoss 0.697705388069 dLossOfReal: 0.587917 dLossOfFake: 0.807494 Time Elapsed: 0:34:21\n",
      "Iteration: 303 gLoss: 0.590642 averageDLoss 0.696812391281 dLossOfReal: 0.586236 dLossOfFake: 0.807389 Time Elapsed: 0:34:29\n",
      "Iteration: 304 gLoss: 0.59073 averageDLoss 0.697233915329 dLossOfReal: 0.587186 dLossOfFake: 0.807282 Time Elapsed: 0:34:36\n",
      "Iteration: 305 gLoss: 0.590811 averageDLoss 0.698203146458 dLossOfReal: 0.589231 dLossOfFake: 0.807176 Time Elapsed: 0:34:43\n",
      "Iteration: 306 gLoss: 0.590898 averageDLoss 0.697278618813 dLossOfReal: 0.587485 dLossOfFake: 0.807072 Time Elapsed: 0:34:51\n",
      "Iteration: 307 gLoss: 0.590981 averageDLoss 0.69777071476 dLossOfReal: 0.588575 dLossOfFake: 0.806966 Time Elapsed: 0:34:58\n",
      "Iteration: 308 gLoss: 0.591066 averageDLoss 0.697236657143 dLossOfReal: 0.587609 dLossOfFake: 0.806864 Time Elapsed: 0:35:05\n",
      "Iteration: 309 gLoss: 0.591149 averageDLoss 0.697526931763 dLossOfReal: 0.588295 dLossOfFake: 0.806759 Time Elapsed: 0:35:12\n",
      "Iteration: 310 gLoss: 0.591234 averageDLoss 0.696493387222 dLossOfReal: 0.58633 dLossOfFake: 0.806657 Time Elapsed: 0:35:20\n",
      "Iteration: 311 gLoss: 0.591317 averageDLoss 0.697205305099 dLossOfReal: 0.587859 dLossOfFake: 0.806552 Time Elapsed: 0:35:27\n",
      "Iteration: 312 gLoss: 0.591399 averageDLoss 0.697536706924 dLossOfReal: 0.588624 dLossOfFake: 0.80645 Time Elapsed: 0:35:34\n",
      "Iteration: 313 gLoss: 0.591483 averageDLoss 0.697106957436 dLossOfReal: 0.587871 dLossOfFake: 0.806343 Time Elapsed: 0:35:42\n",
      "Iteration: 314 gLoss: 0.591566 averageDLoss 0.697416424751 dLossOfReal: 0.588592 dLossOfFake: 0.806241 Time Elapsed: 0:35:49\n",
      "Iteration: 315 gLoss: 0.591652 averageDLoss 0.697422266006 dLossOfReal: 0.588709 dLossOfFake: 0.806136 Time Elapsed: 0:35:57\n",
      "Iteration: 316 gLoss: 0.591733 averageDLoss 0.697001457214 dLossOfReal: 0.587968 dLossOfFake: 0.806035 Time Elapsed: 0:36:04\n",
      "Iteration: 317 gLoss: 0.591815 averageDLoss 0.697129547596 dLossOfReal: 0.588325 dLossOfFake: 0.805934 Time Elapsed: 0:36:11\n",
      "Iteration: 318 gLoss: 0.591898 averageDLoss 0.697102189064 dLossOfReal: 0.588376 dLossOfFake: 0.805828 Time Elapsed: 0:36:19\n",
      "Iteration: 319 gLoss: 0.591979 averageDLoss 0.697168946266 dLossOfReal: 0.588611 dLossOfFake: 0.805727 Time Elapsed: 0:36:26\n",
      "Iteration: 320 gLoss: 0.592062 averageDLoss 0.697032094002 dLossOfReal: 0.588436 dLossOfFake: 0.805629 Time Elapsed: 0:36:33\n",
      "Iteration: 321 gLoss: 0.592144 averageDLoss 0.697426021099 dLossOfReal: 0.589325 dLossOfFake: 0.805527 Time Elapsed: 0:36:41\n",
      "Iteration: 322 gLoss: 0.592226 averageDLoss 0.696672201157 dLossOfReal: 0.587921 dLossOfFake: 0.805423 Time Elapsed: 0:36:48\n",
      "Iteration: 323 gLoss: 0.592308 averageDLoss 0.697615981102 dLossOfReal: 0.58991 dLossOfFake: 0.805322 Time Elapsed: 0:36:56\n",
      "Iteration: 324 gLoss: 0.59239 averageDLoss 0.697166442871 dLossOfReal: 0.589111 dLossOfFake: 0.805222 Time Elapsed: 0:37:03\n",
      "Iteration: 325 gLoss: 0.592474 averageDLoss 0.696887910366 dLossOfReal: 0.588657 dLossOfFake: 0.805119 Time Elapsed: 0:37:11\n",
      "Iteration: 326 gLoss: 0.592553 averageDLoss 0.696875214577 dLossOfReal: 0.588731 dLossOfFake: 0.805019 Time Elapsed: 0:37:18\n",
      "Iteration: 327 gLoss: 0.592632 averageDLoss 0.697621405125 dLossOfReal: 0.590319 dLossOfFake: 0.804924 Time Elapsed: 0:37:26\n",
      "Iteration: 328 gLoss: 0.592711 averageDLoss 0.69720518589 dLossOfReal: 0.589586 dLossOfFake: 0.804824 Time Elapsed: 0:37:33\n",
      "Iteration: 329 gLoss: 0.592792 averageDLoss 0.697022557259 dLossOfReal: 0.589321 dLossOfFake: 0.804725 Time Elapsed: 0:37:41\n",
      "Iteration: 330 gLoss: 0.59287 averageDLoss 0.697473406792 dLossOfReal: 0.590321 dLossOfFake: 0.804626 Time Elapsed: 0:37:48\n",
      "Iteration: 331 gLoss: 0.59295 averageDLoss 0.697266221046 dLossOfReal: 0.590005 dLossOfFake: 0.804527 Time Elapsed: 0:37:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 332 gLoss: 0.593031 averageDLoss 0.697213292122 dLossOfReal: 0.589998 dLossOfFake: 0.804428 Time Elapsed: 0:38:03\n",
      "Iteration: 333 gLoss: 0.593113 averageDLoss 0.697308778763 dLossOfReal: 0.590288 dLossOfFake: 0.80433 Time Elapsed: 0:38:11\n",
      "Iteration: 334 gLoss: 0.59319 averageDLoss 0.697020292282 dLossOfReal: 0.589809 dLossOfFake: 0.804232 Time Elapsed: 0:38:18\n",
      "Iteration: 335 gLoss: 0.593268 averageDLoss 0.696928918362 dLossOfReal: 0.589721 dLossOfFake: 0.804137 Time Elapsed: 0:38:25\n",
      "Iteration: 336 gLoss: 0.593348 averageDLoss 0.696630239487 dLossOfReal: 0.589223 dLossOfFake: 0.804038 Time Elapsed: 0:38:33\n",
      "Iteration: 337 gLoss: 0.593425 averageDLoss 0.697405099869 dLossOfReal: 0.590867 dLossOfFake: 0.803943 Time Elapsed: 0:38:40\n",
      "Iteration: 338 gLoss: 0.593501 averageDLoss 0.697410225868 dLossOfReal: 0.590974 dLossOfFake: 0.803847 Time Elapsed: 0:38:48\n",
      "Iteration: 339 gLoss: 0.593579 averageDLoss 0.697085618973 dLossOfReal: 0.59042 dLossOfFake: 0.803751 Time Elapsed: 0:38:55\n",
      "Iteration: 340 gLoss: 0.593659 averageDLoss 0.696598291397 dLossOfReal: 0.589543 dLossOfFake: 0.803654 Time Elapsed: 0:39:03\n",
      "Iteration: 341 gLoss: 0.593736 averageDLoss 0.69696366787 dLossOfReal: 0.590371 dLossOfFake: 0.803557 Time Elapsed: 0:39:10\n",
      "Iteration: 342 gLoss: 0.593815 averageDLoss 0.697306871414 dLossOfReal: 0.591154 dLossOfFake: 0.803459 Time Elapsed: 0:39:18\n",
      "Iteration: 343 gLoss: 0.593892 averageDLoss 0.696661114693 dLossOfReal: 0.589955 dLossOfFake: 0.803368 Time Elapsed: 0:39:25\n",
      "Iteration: 344 gLoss: 0.59397 averageDLoss 0.697603940964 dLossOfReal: 0.591936 dLossOfFake: 0.803272 Time Elapsed: 0:39:33\n",
      "Iteration: 345 gLoss: 0.594047 averageDLoss 0.69669342041 dLossOfReal: 0.590215 dLossOfFake: 0.803172 Time Elapsed: 0:39:40\n",
      "Iteration: 346 gLoss: 0.594126 averageDLoss 0.697021365166 dLossOfReal: 0.590967 dLossOfFake: 0.803076 Time Elapsed: 0:39:48\n",
      "Iteration: 347 gLoss: 0.594206 averageDLoss 0.697175621986 dLossOfReal: 0.591373 dLossOfFake: 0.802979 Time Elapsed: 0:39:55\n",
      "Iteration: 348 gLoss: 0.594283 averageDLoss 0.696451306343 dLossOfReal: 0.590019 dLossOfFake: 0.802884 Time Elapsed: 0:40:03\n",
      "Iteration: 349 gLoss: 0.594361 averageDLoss 0.696376919746 dLossOfReal: 0.589967 dLossOfFake: 0.802787 Time Elapsed: 0:40:10\n",
      "Iteration: 350 gLoss: 0.594439 averageDLoss 0.697106122971 dLossOfReal: 0.591516 dLossOfFake: 0.802696 Time Elapsed: 0:40:18\n",
      "Iteration: 351 gLoss: 0.594516 averageDLoss 0.696674346924 dLossOfReal: 0.590751 dLossOfFake: 0.802598 Time Elapsed: 0:40:25\n",
      "Iteration: 352 gLoss: 0.594594 averageDLoss 0.69673871994 dLossOfReal: 0.590975 dLossOfFake: 0.802502 Time Elapsed: 0:40:33\n",
      "Iteration: 353 gLoss: 0.594673 averageDLoss 0.696991086006 dLossOfReal: 0.591578 dLossOfFake: 0.802404 Time Elapsed: 0:40:41\n",
      "Iteration: 354 gLoss: 0.594747 averageDLoss 0.696722269058 dLossOfReal: 0.591131 dLossOfFake: 0.802314 Time Elapsed: 0:40:48\n",
      "Iteration: 355 gLoss: 0.594824 averageDLoss 0.696753740311 dLossOfReal: 0.59129 dLossOfFake: 0.802218 Time Elapsed: 0:40:56\n",
      "Iteration: 356 gLoss: 0.594901 averageDLoss 0.696862757206 dLossOfReal: 0.591603 dLossOfFake: 0.802122 Time Elapsed: 0:41:03\n",
      "Iteration: 357 gLoss: 0.594974 averageDLoss 0.696593046188 dLossOfReal: 0.591153 dLossOfFake: 0.802033 Time Elapsed: 0:41:11\n",
      "Iteration: 358 gLoss: 0.595053 averageDLoss 0.695916593075 dLossOfReal: 0.589895 dLossOfFake: 0.801938 Time Elapsed: 0:41:19\n",
      "Iteration: 359 gLoss: 0.595124 averageDLoss 0.696099877357 dLossOfReal: 0.590352 dLossOfFake: 0.801848 Time Elapsed: 0:41:27\n",
      "Iteration: 360 gLoss: 0.595197 averageDLoss 0.697486281395 dLossOfReal: 0.593215 dLossOfFake: 0.801757 Time Elapsed: 0:41:34\n",
      "Iteration: 361 gLoss: 0.595272 averageDLoss 0.696596503258 dLossOfReal: 0.591525 dLossOfFake: 0.801667 Time Elapsed: 0:41:42\n",
      "Iteration: 362 gLoss: 0.595345 averageDLoss 0.69654917717 dLossOfReal: 0.591521 dLossOfFake: 0.801577 Time Elapsed: 0:41:49\n",
      "Iteration: 363 gLoss: 0.59542 averageDLoss 0.696951389313 dLossOfReal: 0.592418 dLossOfFake: 0.801485 Time Elapsed: 0:41:57\n",
      "Iteration: 364 gLoss: 0.595493 averageDLoss 0.696609020233 dLossOfReal: 0.591823 dLossOfFake: 0.801395 Time Elapsed: 0:42:05\n",
      "Iteration: 365 gLoss: 0.595566 averageDLoss 0.696451544762 dLossOfReal: 0.591599 dLossOfFake: 0.801304 Time Elapsed: 0:42:12\n",
      "Iteration: 366 gLoss: 0.595638 averageDLoss 0.696397900581 dLossOfReal: 0.591579 dLossOfFake: 0.801217 Time Elapsed: 0:42:20\n",
      "Iteration: 367 gLoss: 0.595711 averageDLoss 0.697080492973 dLossOfReal: 0.593035 dLossOfFake: 0.801126 Time Elapsed: 0:42:27\n",
      "Iteration: 368 gLoss: 0.595784 averageDLoss 0.696512162685 dLossOfReal: 0.591988 dLossOfFake: 0.801036 Time Elapsed: 0:42:35\n",
      "Iteration: 369 gLoss: 0.595855 averageDLoss 0.696341753006 dLossOfReal: 0.591735 dLossOfFake: 0.800949 Time Elapsed: 0:42:43\n",
      "Iteration: 370 gLoss: 0.595927 averageDLoss 0.696327090263 dLossOfReal: 0.591794 dLossOfFake: 0.80086 Time Elapsed: 0:42:50\n",
      "Iteration: 371 gLoss: 0.596 averageDLoss 0.697075426579 dLossOfReal: 0.59338 dLossOfFake: 0.800771 Time Elapsed: 0:42:58\n",
      "Iteration: 372 gLoss: 0.596074 averageDLoss 0.696301937103 dLossOfReal: 0.591918 dLossOfFake: 0.800686 Time Elapsed: 0:43:06\n",
      "Iteration: 373 gLoss: 0.596144 averageDLoss 0.69625377655 dLossOfReal: 0.591912 dLossOfFake: 0.800595 Time Elapsed: 0:43:13\n",
      "Iteration: 374 gLoss: 0.596218 averageDLoss 0.696727514267 dLossOfReal: 0.592951 dLossOfFake: 0.800504 Time Elapsed: 0:43:21\n",
      "Iteration: 375 gLoss: 0.596287 averageDLoss 0.696245908737 dLossOfReal: 0.592072 dLossOfFake: 0.80042 Time Elapsed: 0:43:29\n",
      "Iteration: 376 gLoss: 0.59636 averageDLoss 0.695751190186 dLossOfReal: 0.591172 dLossOfFake: 0.80033 Time Elapsed: 0:43:36\n",
      "Iteration: 377 gLoss: 0.596432 averageDLoss 0.696650505066 dLossOfReal: 0.593057 dLossOfFake: 0.800244 Time Elapsed: 0:43:44\n",
      "Iteration: 378 gLoss: 0.596506 averageDLoss 0.696863412857 dLossOfReal: 0.593575 dLossOfFake: 0.800152 Time Elapsed: 0:43:52\n",
      "Iteration: 379 gLoss: 0.596574 averageDLoss 0.696547150612 dLossOfReal: 0.593027 dLossOfFake: 0.800067 Time Elapsed: 0:43:59\n",
      "Iteration: 380 gLoss: 0.596645 averageDLoss 0.695604979992 dLossOfReal: 0.591229 dLossOfFake: 0.79998 Time Elapsed: 0:44:07\n",
      "Iteration: 381 gLoss: 0.596717 averageDLoss 0.695464253426 dLossOfReal: 0.591037 dLossOfFake: 0.799892 Time Elapsed: 0:44:15\n",
      "Iteration: 382 gLoss: 0.596788 averageDLoss 0.69615405798 dLossOfReal: 0.592503 dLossOfFake: 0.799805 Time Elapsed: 0:44:22\n",
      "Iteration: 383 gLoss: 0.596862 averageDLoss 0.69592654705 dLossOfReal: 0.592138 dLossOfFake: 0.799715 Time Elapsed: 0:44:30\n",
      "Iteration: 384 gLoss: 0.596934 averageDLoss 0.695842921734 dLossOfReal: 0.59206 dLossOfFake: 0.799626 Time Elapsed: 0:44:38\n",
      "Iteration: 385 gLoss: 0.597007 averageDLoss 0.696159601212 dLossOfReal: 0.592782 dLossOfFake: 0.799538 Time Elapsed: 0:44:45\n",
      "Iteration: 386 gLoss: 0.597075 averageDLoss 0.695598602295 dLossOfReal: 0.591745 dLossOfFake: 0.799452 Time Elapsed: 0:44:53\n",
      "Iteration: 387 gLoss: 0.597146 averageDLoss 0.696502566338 dLossOfReal: 0.593638 dLossOfFake: 0.799367 Time Elapsed: 0:45:01\n",
      "Iteration: 388 gLoss: 0.597215 averageDLoss 0.695968747139 dLossOfReal: 0.592655 dLossOfFake: 0.799282 Time Elapsed: 0:45:08\n",
      "Iteration: 389 gLoss: 0.597286 averageDLoss 0.696485519409 dLossOfReal: 0.593776 dLossOfFake: 0.799195 Time Elapsed: 0:45:16\n",
      "Iteration: 390 gLoss: 0.597358 averageDLoss 0.695919752121 dLossOfReal: 0.592731 dLossOfFake: 0.799108 Time Elapsed: 0:45:24\n",
      "Iteration: 391 gLoss: 0.597425 averageDLoss 0.695364713669 dLossOfReal: 0.591703 dLossOfFake: 0.799027 Time Elapsed: 0:45:32\n",
      "Iteration: 392 gLoss: 0.597497 averageDLoss 0.696485877037 dLossOfReal: 0.594034 dLossOfFake: 0.798938 Time Elapsed: 0:45:39\n",
      "Iteration: 393 gLoss: 0.597567 averageDLoss 0.695999324322 dLossOfReal: 0.593145 dLossOfFake: 0.798853 Time Elapsed: 0:45:47\n",
      "Iteration: 394 gLoss: 0.597635 averageDLoss 0.695997953415 dLossOfReal: 0.59323 dLossOfFake: 0.798766 Time Elapsed: 0:45:55\n",
      "Iteration: 395 gLoss: 0.597706 averageDLoss 0.6965097785 dLossOfReal: 0.594337 dLossOfFake: 0.798683 Time Elapsed: 0:46:03\n",
      "Iteration: 396 gLoss: 0.597776 averageDLoss 0.69607257843 dLossOfReal: 0.59355 dLossOfFake: 0.798595 Time Elapsed: 0:46:11\n",
      "Iteration: 397 gLoss: 0.597845 averageDLoss 0.696313738823 dLossOfReal: 0.594115 dLossOfFake: 0.798513 Time Elapsed: 0:46:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 398 gLoss: 0.597916 averageDLoss 0.69612288475 dLossOfReal: 0.593821 dLossOfFake: 0.798424 Time Elapsed: 0:46:27\n",
      "Iteration: 399 gLoss: 0.597984 averageDLoss 0.695808887482 dLossOfReal: 0.593276 dLossOfFake: 0.798342 Time Elapsed: 0:46:35\n",
      "Iteration: 400 gLoss: 0.598054 averageDLoss 0.695989847183 dLossOfReal: 0.593724 dLossOfFake: 0.798256 Time Elapsed: 0:46:43\n",
      "Iteration: 401 gLoss: 0.598121 averageDLoss 0.69655328989 dLossOfReal: 0.594933 dLossOfFake: 0.798173 Time Elapsed: 0:46:50\n",
      "Iteration: 402 gLoss: 0.59819 averageDLoss 0.695908784866 dLossOfReal: 0.593728 dLossOfFake: 0.798089 Time Elapsed: 0:46:58\n",
      "Iteration: 403 gLoss: 0.598259 averageDLoss 0.695309281349 dLossOfReal: 0.592613 dLossOfFake: 0.798006 Time Elapsed: 0:47:06\n",
      "Iteration: 404 gLoss: 0.598333 averageDLoss 0.695792257786 dLossOfReal: 0.593668 dLossOfFake: 0.797917 Time Elapsed: 0:47:14\n",
      "Iteration: 405 gLoss: 0.598402 averageDLoss 0.695932149887 dLossOfReal: 0.594031 dLossOfFake: 0.797833 Time Elapsed: 0:47:21\n",
      "Iteration: 406 gLoss: 0.59847 averageDLoss 0.695851266384 dLossOfReal: 0.593951 dLossOfFake: 0.797751 Time Elapsed: 0:47:29\n",
      "Iteration: 407 gLoss: 0.598537 averageDLoss 0.696171462536 dLossOfReal: 0.594676 dLossOfFake: 0.797667 Time Elapsed: 0:47:37\n",
      "Iteration: 408 gLoss: 0.598604 averageDLoss 0.695561170578 dLossOfReal: 0.593536 dLossOfFake: 0.797586 Time Elapsed: 0:47:45\n",
      "Iteration: 409 gLoss: 0.598671 averageDLoss 0.696055173874 dLossOfReal: 0.594609 dLossOfFake: 0.797501 Time Elapsed: 0:47:53\n",
      "Iteration: 410 gLoss: 0.598739 averageDLoss 0.695642709732 dLossOfReal: 0.593864 dLossOfFake: 0.797421 Time Elapsed: 0:48:00\n",
      "Iteration: 411 gLoss: 0.598807 averageDLoss 0.695514798164 dLossOfReal: 0.593695 dLossOfFake: 0.797335 Time Elapsed: 0:48:08\n",
      "Iteration: 412 gLoss: 0.598873 averageDLoss 0.695676207542 dLossOfReal: 0.594097 dLossOfFake: 0.797255 Time Elapsed: 0:48:16\n",
      "Iteration: 413 gLoss: 0.598939 averageDLoss 0.695534467697 dLossOfReal: 0.593893 dLossOfFake: 0.797176 Time Elapsed: 0:48:24\n",
      "Iteration: 414 gLoss: 0.59901 averageDLoss 0.696230530739 dLossOfReal: 0.595371 dLossOfFake: 0.79709 Time Elapsed: 0:48:31\n",
      "Iteration: 415 gLoss: 0.599077 averageDLoss 0.696422457695 dLossOfReal: 0.595838 dLossOfFake: 0.797007 Time Elapsed: 0:48:39\n",
      "Iteration: 416 gLoss: 0.599144 averageDLoss 0.696773052216 dLossOfReal: 0.596619 dLossOfFake: 0.796927 Time Elapsed: 0:48:47\n",
      "Iteration: 417 gLoss: 0.599206 averageDLoss 0.696399748325 dLossOfReal: 0.595948 dLossOfFake: 0.796851 Time Elapsed: 0:48:55\n",
      "Iteration: 418 gLoss: 0.599272 averageDLoss 0.695496320724 dLossOfReal: 0.594223 dLossOfFake: 0.796769 Time Elapsed: 0:49:03\n",
      "Iteration: 419 gLoss: 0.599339 averageDLoss 0.696315228939 dLossOfReal: 0.59594 dLossOfFake: 0.79669 Time Elapsed: 0:49:10\n",
      "Iteration: 420 gLoss: 0.599406 averageDLoss 0.695902645588 dLossOfReal: 0.595198 dLossOfFake: 0.796607 Time Elapsed: 0:49:18\n",
      "Iteration: 421 gLoss: 0.599473 averageDLoss 0.695599019527 dLossOfReal: 0.594671 dLossOfFake: 0.796527 Time Elapsed: 0:49:26\n",
      "Iteration: 422 gLoss: 0.599536 averageDLoss 0.696153640747 dLossOfReal: 0.595858 dLossOfFake: 0.796449 Time Elapsed: 0:49:34\n",
      "Iteration: 423 gLoss: 0.599603 averageDLoss 0.695864081383 dLossOfReal: 0.595362 dLossOfFake: 0.796366 Time Elapsed: 0:49:43\n",
      "Iteration: 424 gLoss: 0.599671 averageDLoss 0.695740461349 dLossOfReal: 0.595194 dLossOfFake: 0.796286 Time Elapsed: 0:49:50\n",
      "Iteration: 425 gLoss: 0.599734 averageDLoss 0.695892632008 dLossOfReal: 0.595577 dLossOfFake: 0.796209 Time Elapsed: 0:49:58\n",
      "Iteration: 426 gLoss: 0.5998 averageDLoss 0.695100188255 dLossOfReal: 0.594075 dLossOfFake: 0.796126 Time Elapsed: 0:50:06\n",
      "Iteration: 427 gLoss: 0.599864 averageDLoss 0.695845484734 dLossOfReal: 0.595641 dLossOfFake: 0.79605 Time Elapsed: 0:50:14\n",
      "Iteration: 428 gLoss: 0.599927 averageDLoss 0.695878148079 dLossOfReal: 0.595787 dLossOfFake: 0.795969 Time Elapsed: 0:50:21\n",
      "Iteration: 429 gLoss: 0.599992 averageDLoss 0.695931196213 dLossOfReal: 0.595969 dLossOfFake: 0.795894 Time Elapsed: 0:50:29\n",
      "Iteration: 430 gLoss: 0.600054 averageDLoss 0.695506691933 dLossOfReal: 0.595199 dLossOfFake: 0.795815 Time Elapsed: 0:50:37\n",
      "Iteration: 431 gLoss: 0.600123 averageDLoss 0.695580840111 dLossOfReal: 0.595425 dLossOfFake: 0.795737 Time Elapsed: 0:50:44\n",
      "Iteration: 432 gLoss: 0.600182 averageDLoss 0.695085287094 dLossOfReal: 0.594508 dLossOfFake: 0.795662 Time Elapsed: 0:50:52\n",
      "Iteration: 433 gLoss: 0.600244 averageDLoss 0.695360779762 dLossOfReal: 0.595134 dLossOfFake: 0.795587 Time Elapsed: 0:51:00\n",
      "Iteration: 434 gLoss: 0.600311 averageDLoss 0.695850193501 dLossOfReal: 0.596192 dLossOfFake: 0.795508 Time Elapsed: 0:51:08\n",
      "Iteration: 435 gLoss: 0.600373 averageDLoss 0.695552229881 dLossOfReal: 0.595677 dLossOfFake: 0.795427 Time Elapsed: 0:51:16\n",
      "Iteration: 436 gLoss: 0.600437 averageDLoss 0.695793688297 dLossOfReal: 0.596234 dLossOfFake: 0.795354 Time Elapsed: 0:51:24\n",
      "Iteration: 437 gLoss: 0.600501 averageDLoss 0.695692658424 dLossOfReal: 0.59611 dLossOfFake: 0.795275 Time Elapsed: 0:51:32\n",
      "Iteration: 438 gLoss: 0.600563 averageDLoss 0.695956766605 dLossOfReal: 0.596715 dLossOfFake: 0.795198 Time Elapsed: 0:51:39\n",
      "Iteration: 439 gLoss: 0.600625 averageDLoss 0.695487678051 dLossOfReal: 0.595852 dLossOfFake: 0.795123 Time Elapsed: 0:51:47\n",
      "Iteration: 440 gLoss: 0.60069 averageDLoss 0.695196866989 dLossOfReal: 0.59535 dLossOfFake: 0.795044 Time Elapsed: 0:51:55\n",
      "Iteration: 441 gLoss: 0.60075 averageDLoss 0.695307314396 dLossOfReal: 0.595643 dLossOfFake: 0.794972 Time Elapsed: 0:52:03\n",
      "Iteration: 442 gLoss: 0.600811 averageDLoss 0.695601224899 dLossOfReal: 0.596304 dLossOfFake: 0.794898 Time Elapsed: 0:52:10\n",
      "Iteration: 443 gLoss: 0.600875 averageDLoss 0.695098519325 dLossOfReal: 0.595376 dLossOfFake: 0.794821 Time Elapsed: 0:52:18\n",
      "Iteration: 444 gLoss: 0.600938 averageDLoss 0.695384919643 dLossOfReal: 0.596025 dLossOfFake: 0.794744 Time Elapsed: 0:52:26\n",
      "Iteration: 445 gLoss: 0.600999 averageDLoss 0.695306479931 dLossOfReal: 0.595944 dLossOfFake: 0.794669 Time Elapsed: 0:52:34\n",
      "Iteration: 446 gLoss: 0.601062 averageDLoss 0.695338487625 dLossOfReal: 0.596082 dLossOfFake: 0.794595 Time Elapsed: 0:52:41\n",
      "Iteration: 447 gLoss: 0.601127 averageDLoss 0.695442140102 dLossOfReal: 0.596367 dLossOfFake: 0.794517 Time Elapsed: 0:52:49\n",
      "Iteration: 448 gLoss: 0.601189 averageDLoss 0.695425629616 dLossOfReal: 0.596411 dLossOfFake: 0.79444 Time Elapsed: 0:52:57\n",
      "Iteration: 449 gLoss: 0.60125 averageDLoss 0.695313513279 dLossOfReal: 0.596262 dLossOfFake: 0.794365 Time Elapsed: 0:53:04\n",
      "Iteration: 450 gLoss: 0.601309 averageDLoss 0.695067167282 dLossOfReal: 0.59584 dLossOfFake: 0.794294 Time Elapsed: 0:53:12\n",
      "Iteration: 451 gLoss: 0.60137 averageDLoss 0.695074260235 dLossOfReal: 0.595927 dLossOfFake: 0.794221 Time Elapsed: 0:53:20\n",
      "Iteration: 452 gLoss: 0.60143 averageDLoss 0.696077823639 dLossOfReal: 0.59801 dLossOfFake: 0.794145 Time Elapsed: 0:53:28\n",
      "Iteration: 453 gLoss: 0.60149 averageDLoss 0.695567131042 dLossOfReal: 0.597062 dLossOfFake: 0.794073 Time Elapsed: 0:53:35\n",
      "Iteration: 454 gLoss: 0.601557 averageDLoss 0.695007562637 dLossOfReal: 0.596022 dLossOfFake: 0.793993 Time Elapsed: 0:53:43\n",
      "Iteration: 455 gLoss: 0.601617 averageDLoss 0.695698022842 dLossOfReal: 0.597477 dLossOfFake: 0.793919 Time Elapsed: 0:53:51\n",
      "Iteration: 456 gLoss: 0.601675 averageDLoss 0.695295333862 dLossOfReal: 0.596741 dLossOfFake: 0.793849 Time Elapsed: 0:53:59\n",
      "Iteration: 457 gLoss: 0.601735 averageDLoss 0.694930613041 dLossOfReal: 0.596083 dLossOfFake: 0.793778 Time Elapsed: 0:54:06\n",
      "Iteration: 458 gLoss: 0.601795 averageDLoss 0.695695340633 dLossOfReal: 0.597688 dLossOfFake: 0.793703 Time Elapsed: 0:54:14\n",
      "Iteration: 459 gLoss: 0.601853 averageDLoss 0.695134043694 dLossOfReal: 0.596637 dLossOfFake: 0.793631 Time Elapsed: 0:54:22\n",
      "Iteration: 460 gLoss: 0.601918 averageDLoss 0.696024119854 dLossOfReal: 0.598493 dLossOfFake: 0.793556 Time Elapsed: 0:54:30\n",
      "Iteration: 461 gLoss: 0.60198 averageDLoss 0.695129513741 dLossOfReal: 0.596778 dLossOfFake: 0.793481 Time Elapsed: 0:54:38\n",
      "Iteration: 462 gLoss: 0.602041 averageDLoss 0.695709943771 dLossOfReal: 0.598013 dLossOfFake: 0.793407 Time Elapsed: 0:54:45\n",
      "Iteration: 463 gLoss: 0.602096 averageDLoss 0.695032119751 dLossOfReal: 0.596725 dLossOfFake: 0.793339 Time Elapsed: 0:54:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 464 gLoss: 0.602158 averageDLoss 0.69529402256 dLossOfReal: 0.597324 dLossOfFake: 0.793264 Time Elapsed: 0:55:01\n",
      "Iteration: 465 gLoss: 0.602219 averageDLoss 0.695033311844 dLossOfReal: 0.596878 dLossOfFake: 0.793189 Time Elapsed: 0:55:09\n",
      "Iteration: 466 gLoss: 0.60228 averageDLoss 0.695011973381 dLossOfReal: 0.596905 dLossOfFake: 0.793119 Time Elapsed: 0:55:16\n",
      "Iteration: 467 gLoss: 0.602338 averageDLoss 0.69519007206 dLossOfReal: 0.597334 dLossOfFake: 0.793046 Time Elapsed: 0:55:24\n",
      "Iteration: 468 gLoss: 0.602395 averageDLoss 0.695547521114 dLossOfReal: 0.598119 dLossOfFake: 0.792976 Time Elapsed: 0:55:32\n",
      "Iteration: 469 gLoss: 0.602457 averageDLoss 0.695203900337 dLossOfReal: 0.597506 dLossOfFake: 0.792901 Time Elapsed: 0:55:40\n",
      "Iteration: 470 gLoss: 0.602517 averageDLoss 0.695641040802 dLossOfReal: 0.598452 dLossOfFake: 0.79283 Time Elapsed: 0:55:48\n",
      "Iteration: 471 gLoss: 0.602573 averageDLoss 0.69461786747 dLossOfReal: 0.596473 dLossOfFake: 0.792762 Time Elapsed: 0:55:55\n",
      "Iteration: 472 gLoss: 0.602629 averageDLoss 0.694671630859 dLossOfReal: 0.596652 dLossOfFake: 0.792692 Time Elapsed: 0:56:03\n",
      "Iteration: 473 gLoss: 0.602689 averageDLoss 0.694702386856 dLossOfReal: 0.596784 dLossOfFake: 0.792621 Time Elapsed: 0:56:11\n",
      "Iteration: 474 gLoss: 0.60275 averageDLoss 0.695421278477 dLossOfReal: 0.598295 dLossOfFake: 0.792548 Time Elapsed: 0:56:19\n",
      "Iteration: 475 gLoss: 0.602808 averageDLoss 0.695526123047 dLossOfReal: 0.598572 dLossOfFake: 0.792481 Time Elapsed: 0:56:27\n",
      "Iteration: 476 gLoss: 0.602863 averageDLoss 0.694815635681 dLossOfReal: 0.59722 dLossOfFake: 0.792411 Time Elapsed: 0:56:35\n",
      "Iteration: 477 gLoss: 0.602923 averageDLoss 0.695429563522 dLossOfReal: 0.59852 dLossOfFake: 0.792339 Time Elapsed: 0:56:43\n",
      "Iteration: 478 gLoss: 0.60298 averageDLoss 0.695739626884 dLossOfReal: 0.59921 dLossOfFake: 0.79227 Time Elapsed: 0:56:51\n",
      "Iteration: 479 gLoss: 0.60304 averageDLoss 0.695692539215 dLossOfReal: 0.599187 dLossOfFake: 0.792198 Time Elapsed: 0:56:59\n",
      "Iteration: 480 gLoss: 0.603099 averageDLoss 0.695885658264 dLossOfReal: 0.599643 dLossOfFake: 0.792128 Time Elapsed: 0:57:07\n",
      "Iteration: 481 gLoss: 0.603156 averageDLoss 0.694636702538 dLossOfReal: 0.597214 dLossOfFake: 0.79206 Time Elapsed: 0:57:15\n",
      "Iteration: 482 gLoss: 0.603209 averageDLoss 0.694892048836 dLossOfReal: 0.597793 dLossOfFake: 0.791991 Time Elapsed: 0:57:22\n",
      "Iteration: 483 gLoss: 0.603268 averageDLoss 0.695283770561 dLossOfReal: 0.598644 dLossOfFake: 0.791923 Time Elapsed: 0:57:31\n",
      "Iteration: 484 gLoss: 0.603327 averageDLoss 0.695614397526 dLossOfReal: 0.599376 dLossOfFake: 0.791853 Time Elapsed: 0:57:39\n",
      "Iteration: 485 gLoss: 0.603384 averageDLoss 0.695432305336 dLossOfReal: 0.599082 dLossOfFake: 0.791783 Time Elapsed: 0:57:47\n",
      "Iteration: 486 gLoss: 0.603441 averageDLoss 0.694677233696 dLossOfReal: 0.597641 dLossOfFake: 0.791714 Time Elapsed: 0:57:55\n",
      "Iteration: 487 gLoss: 0.603498 averageDLoss 0.694650709629 dLossOfReal: 0.597657 dLossOfFake: 0.791644 Time Elapsed: 0:58:03\n",
      "Iteration: 488 gLoss: 0.603556 averageDLoss 0.695343375206 dLossOfReal: 0.599111 dLossOfFake: 0.791576 Time Elapsed: 0:58:11\n",
      "Iteration: 489 gLoss: 0.603615 averageDLoss 0.694711863995 dLossOfReal: 0.59792 dLossOfFake: 0.791504 Time Elapsed: 0:58:19\n",
      "Iteration: 490 gLoss: 0.603672 averageDLoss 0.695049166679 dLossOfReal: 0.598663 dLossOfFake: 0.791435 Time Elapsed: 0:58:27\n",
      "Iteration: 491 gLoss: 0.603729 averageDLoss 0.695651769638 dLossOfReal: 0.599938 dLossOfFake: 0.791365 Time Elapsed: 0:58:35\n",
      "Iteration: 492 gLoss: 0.603787 averageDLoss 0.694524288177 dLossOfReal: 0.597752 dLossOfFake: 0.791297 Time Elapsed: 0:58:43\n",
      "Iteration: 493 gLoss: 0.603843 averageDLoss 0.694841384888 dLossOfReal: 0.598455 dLossOfFake: 0.791228 Time Elapsed: 0:58:51\n",
      "Iteration: 494 gLoss: 0.603898 averageDLoss 0.694495797157 dLossOfReal: 0.597832 dLossOfFake: 0.791159 Time Elapsed: 0:58:59\n",
      "Iteration: 495 gLoss: 0.603958 averageDLoss 0.695345818996 dLossOfReal: 0.5996 dLossOfFake: 0.791092 Time Elapsed: 0:59:07\n",
      "Iteration: 496 gLoss: 0.604013 averageDLoss 0.694805502892 dLossOfReal: 0.598588 dLossOfFake: 0.791023 Time Elapsed: 0:59:15\n",
      "Iteration: 497 gLoss: 0.604068 averageDLoss 0.694398999214 dLossOfReal: 0.597842 dLossOfFake: 0.790956 Time Elapsed: 0:59:23\n",
      "Iteration: 498 gLoss: 0.604128 averageDLoss 0.695177316666 dLossOfReal: 0.599468 dLossOfFake: 0.790887 Time Elapsed: 0:59:31\n",
      "Iteration: 499 gLoss: 0.604181 averageDLoss 0.69460439682 dLossOfReal: 0.598387 dLossOfFake: 0.790821 Time Elapsed: 0:59:39\n",
      "Iteration: 500 gLoss: 0.604237 averageDLoss 0.69559442997 dLossOfReal: 0.600438 dLossOfFake: 0.790751 Time Elapsed: 0:59:47\n",
      "Iteration: 501 gLoss: 0.604293 averageDLoss 0.695128321648 dLossOfReal: 0.599571 dLossOfFake: 0.790686 Time Elapsed: 0:59:55\n",
      "Iteration: 502 gLoss: 0.604347 averageDLoss 0.694742441177 dLossOfReal: 0.598866 dLossOfFake: 0.790619 Time Elapsed: 1:00:03\n",
      "Iteration: 503 gLoss: 0.6044 averageDLoss 0.694462060928 dLossOfReal: 0.598368 dLossOfFake: 0.790557 Time Elapsed: 1:00:11\n",
      "Iteration: 504 gLoss: 0.604456 averageDLoss 0.694990217686 dLossOfReal: 0.599492 dLossOfFake: 0.790488 Time Elapsed: 1:00:19\n",
      "Iteration: 505 gLoss: 0.604511 averageDLoss 0.694861650467 dLossOfReal: 0.599303 dLossOfFake: 0.790421 Time Elapsed: 1:00:27\n",
      "Iteration: 506 gLoss: 0.604568 averageDLoss 0.694906651974 dLossOfReal: 0.599457 dLossOfFake: 0.790356 Time Elapsed: 1:00:35\n",
      "Iteration: 507 gLoss: 0.604624 averageDLoss 0.69481921196 dLossOfReal: 0.599349 dLossOfFake: 0.79029 Time Elapsed: 1:00:43\n",
      "Iteration: 508 gLoss: 0.604677 averageDLoss 0.695470809937 dLossOfReal: 0.60072 dLossOfFake: 0.790222 Time Elapsed: 1:00:51\n",
      "Iteration: 509 gLoss: 0.604733 averageDLoss 0.694822013378 dLossOfReal: 0.599488 dLossOfFake: 0.790156 Time Elapsed: 1:00:59\n",
      "Iteration: 510 gLoss: 0.604786 averageDLoss 0.695246577263 dLossOfReal: 0.600403 dLossOfFake: 0.790091 Time Elapsed: 1:01:07\n",
      "Iteration: 511 gLoss: 0.60484 averageDLoss 0.695200741291 dLossOfReal: 0.600376 dLossOfFake: 0.790026 Time Elapsed: 1:01:16\n",
      "Iteration: 512 gLoss: 0.604898 averageDLoss 0.694931268692 dLossOfReal: 0.599903 dLossOfFake: 0.78996 Time Elapsed: 1:01:24\n",
      "Iteration: 513 gLoss: 0.604947 averageDLoss 0.695056319237 dLossOfReal: 0.600215 dLossOfFake: 0.789898 Time Elapsed: 1:01:32\n",
      "Iteration: 514 gLoss: 0.605001 averageDLoss 0.694935679436 dLossOfReal: 0.60004 dLossOfFake: 0.789831 Time Elapsed: 1:01:40\n",
      "Iteration: 515 gLoss: 0.605053 averageDLoss 0.695055484772 dLossOfReal: 0.600341 dLossOfFake: 0.78977 Time Elapsed: 1:01:48\n",
      "Iteration: 516 gLoss: 0.605107 averageDLoss 0.693914294243 dLossOfReal: 0.598123 dLossOfFake: 0.789705 Time Elapsed: 1:01:56\n",
      "Iteration: 517 gLoss: 0.605159 averageDLoss 0.694944083691 dLossOfReal: 0.600245 dLossOfFake: 0.789644 Time Elapsed: 1:02:04\n",
      "Iteration: 518 gLoss: 0.605214 averageDLoss 0.694074988365 dLossOfReal: 0.598575 dLossOfFake: 0.789575 Time Elapsed: 1:02:12\n",
      "Iteration: 519 gLoss: 0.605268 averageDLoss 0.69499540329 dLossOfReal: 0.60048 dLossOfFake: 0.789511 Time Elapsed: 1:02:20\n",
      "Iteration: 520 gLoss: 0.60532 averageDLoss 0.695123076439 dLossOfReal: 0.600798 dLossOfFake: 0.789449 Time Elapsed: 1:02:28\n",
      "Iteration: 521 gLoss: 0.605373 averageDLoss 0.695015251637 dLossOfReal: 0.600644 dLossOfFake: 0.789386 Time Elapsed: 1:02:36\n",
      "Iteration: 522 gLoss: 0.605425 averageDLoss 0.694578170776 dLossOfReal: 0.599834 dLossOfFake: 0.789322 Time Elapsed: 1:02:44\n",
      "Iteration: 523 gLoss: 0.605479 averageDLoss 0.694241344929 dLossOfReal: 0.599225 dLossOfFake: 0.789258 Time Elapsed: 1:02:52\n",
      "Iteration: 524 gLoss: 0.605531 averageDLoss 0.694700360298 dLossOfReal: 0.600205 dLossOfFake: 0.789195 Time Elapsed: 1:03:00\n",
      "Iteration: 525 gLoss: 0.605586 averageDLoss 0.694936990738 dLossOfReal: 0.600744 dLossOfFake: 0.78913 Time Elapsed: 1:03:09\n",
      "Iteration: 526 gLoss: 0.605637 averageDLoss 0.694671273232 dLossOfReal: 0.600274 dLossOfFake: 0.789069 Time Elapsed: 1:03:17\n",
      "Iteration: 527 gLoss: 0.60569 averageDLoss 0.694861412048 dLossOfReal: 0.600719 dLossOfFake: 0.789004 Time Elapsed: 1:03:25\n",
      "Iteration: 528 gLoss: 0.605742 averageDLoss 0.694530427456 dLossOfReal: 0.600119 dLossOfFake: 0.788942 Time Elapsed: 1:03:33\n",
      "Iteration: 529 gLoss: 0.605795 averageDLoss 0.695687413216 dLossOfReal: 0.602493 dLossOfFake: 0.788882 Time Elapsed: 1:03:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 530 gLoss: 0.605847 averageDLoss 0.695145606995 dLossOfReal: 0.601477 dLossOfFake: 0.788814 Time Elapsed: 1:03:50\n",
      "Iteration: 531 gLoss: 0.6059 averageDLoss 0.694745481014 dLossOfReal: 0.600738 dLossOfFake: 0.788753 Time Elapsed: 1:03:58\n",
      "Iteration: 532 gLoss: 0.605952 averageDLoss 0.694909930229 dLossOfReal: 0.60113 dLossOfFake: 0.78869 Time Elapsed: 1:04:06\n",
      "Iteration: 533 gLoss: 0.606002 averageDLoss 0.694788455963 dLossOfReal: 0.600948 dLossOfFake: 0.788629 Time Elapsed: 1:04:15\n",
      "Iteration: 534 gLoss: 0.606054 averageDLoss 0.694536089897 dLossOfReal: 0.600502 dLossOfFake: 0.78857 Time Elapsed: 1:04:23\n",
      "Iteration: 535 gLoss: 0.606104 averageDLoss 0.695360422134 dLossOfReal: 0.602213 dLossOfFake: 0.788508 Time Elapsed: 1:04:31\n",
      "Iteration: 536 gLoss: 0.606155 averageDLoss 0.694482386112 dLossOfReal: 0.600518 dLossOfFake: 0.788447 Time Elapsed: 1:04:39\n",
      "Iteration: 537 gLoss: 0.606206 averageDLoss 0.695065617561 dLossOfReal: 0.601745 dLossOfFake: 0.788386 Time Elapsed: 1:04:48\n",
      "Iteration: 538 gLoss: 0.606255 averageDLoss 0.694594025612 dLossOfReal: 0.600864 dLossOfFake: 0.788324 Time Elapsed: 1:04:56\n",
      "Iteration: 539 gLoss: 0.606307 averageDLoss 0.694376468658 dLossOfReal: 0.600489 dLossOfFake: 0.788264 Time Elapsed: 1:05:04\n",
      "Iteration: 540 gLoss: 0.606361 averageDLoss 0.694566726685 dLossOfReal: 0.600933 dLossOfFake: 0.788201 Time Elapsed: 1:05:12\n",
      "Iteration: 541 gLoss: 0.60641 averageDLoss 0.695104718208 dLossOfReal: 0.60207 dLossOfFake: 0.788139 Time Elapsed: 1:05:21\n",
      "Iteration: 542 gLoss: 0.60646 averageDLoss 0.694213986397 dLossOfReal: 0.600347 dLossOfFake: 0.78808 Time Elapsed: 1:05:29\n",
      "Iteration: 543 gLoss: 0.60651 averageDLoss 0.694906949997 dLossOfReal: 0.601795 dLossOfFake: 0.788019 Time Elapsed: 1:05:37\n",
      "Iteration: 544 gLoss: 0.606562 averageDLoss 0.69415050745 dLossOfReal: 0.600343 dLossOfFake: 0.787958 Time Elapsed: 1:05:46\n",
      "Iteration: 545 gLoss: 0.606611 averageDLoss 0.694711089134 dLossOfReal: 0.601522 dLossOfFake: 0.7879 Time Elapsed: 1:05:54\n",
      "Iteration: 546 gLoss: 0.606659 averageDLoss 0.695068001747 dLossOfReal: 0.602294 dLossOfFake: 0.787842 Time Elapsed: 1:06:02\n",
      "Iteration: 547 gLoss: 0.606707 averageDLoss 0.695042550564 dLossOfReal: 0.602301 dLossOfFake: 0.787784 Time Elapsed: 1:06:10\n",
      "Iteration: 548 gLoss: 0.606756 averageDLoss 0.695031762123 dLossOfReal: 0.602339 dLossOfFake: 0.787724 Time Elapsed: 1:06:19\n",
      "Iteration: 549 gLoss: 0.606807 averageDLoss 0.693948745728 dLossOfReal: 0.600235 dLossOfFake: 0.787662 Time Elapsed: 1:06:28\n",
      "Iteration: 550 gLoss: 0.606858 averageDLoss 0.693539261818 dLossOfReal: 0.599477 dLossOfFake: 0.787602 Time Elapsed: 1:06:36\n",
      "Iteration: 551 gLoss: 0.606909 averageDLoss 0.694439172745 dLossOfReal: 0.601337 dLossOfFake: 0.787541 Time Elapsed: 1:06:44\n",
      "Iteration: 552 gLoss: 0.60696 averageDLoss 0.69471180439 dLossOfReal: 0.601942 dLossOfFake: 0.787481 Time Elapsed: 1:06:53\n",
      "Iteration: 553 gLoss: 0.607008 averageDLoss 0.694758474827 dLossOfReal: 0.602094 dLossOfFake: 0.787423 Time Elapsed: 1:07:01\n",
      "Iteration: 554 gLoss: 0.607057 averageDLoss 0.695267558098 dLossOfReal: 0.603171 dLossOfFake: 0.787364 Time Elapsed: 1:07:09\n",
      "Iteration: 555 gLoss: 0.607106 averageDLoss 0.694689154625 dLossOfReal: 0.602072 dLossOfFake: 0.787307 Time Elapsed: 1:07:18\n",
      "Iteration: 556 gLoss: 0.607156 averageDLoss 0.694315373898 dLossOfReal: 0.601385 dLossOfFake: 0.787245 Time Elapsed: 1:07:26\n",
      "Iteration: 557 gLoss: 0.607205 averageDLoss 0.694895505905 dLossOfReal: 0.602604 dLossOfFake: 0.787187 Time Elapsed: 1:07:34\n",
      "Iteration: 558 gLoss: 0.607254 averageDLoss 0.694449186325 dLossOfReal: 0.60177 dLossOfFake: 0.787129 Time Elapsed: 1:07:42\n",
      "Iteration: 559 gLoss: 0.607303 averageDLoss 0.694139242172 dLossOfReal: 0.601209 dLossOfFake: 0.78707 Time Elapsed: 1:07:51\n",
      "Iteration: 560 gLoss: 0.607353 averageDLoss 0.694728732109 dLossOfReal: 0.602445 dLossOfFake: 0.787012 Time Elapsed: 1:07:59\n",
      "Iteration: 561 gLoss: 0.607401 averageDLoss 0.694129526615 dLossOfReal: 0.601304 dLossOfFake: 0.786955 Time Elapsed: 1:08:07\n",
      "Iteration: 562 gLoss: 0.607448 averageDLoss 0.694054365158 dLossOfReal: 0.601211 dLossOfFake: 0.786898 Time Elapsed: 1:08:16\n",
      "Iteration: 563 gLoss: 0.607496 averageDLoss 0.694393575191 dLossOfReal: 0.601947 dLossOfFake: 0.78684 Time Elapsed: 1:08:24\n",
      "Iteration: 564 gLoss: 0.607545 averageDLoss 0.69440549612 dLossOfReal: 0.602029 dLossOfFake: 0.786782 Time Elapsed: 1:08:33\n",
      "Iteration: 565 gLoss: 0.607595 averageDLoss 0.694475650787 dLossOfReal: 0.602231 dLossOfFake: 0.78672 Time Elapsed: 1:08:41\n",
      "Iteration: 566 gLoss: 0.60764 averageDLoss 0.694198131561 dLossOfReal: 0.601729 dLossOfFake: 0.786667 Time Elapsed: 1:08:49\n",
      "Iteration: 567 gLoss: 0.607689 averageDLoss 0.694693863392 dLossOfReal: 0.602779 dLossOfFake: 0.786609 Time Elapsed: 1:08:58\n",
      "Iteration: 568 gLoss: 0.607736 averageDLoss 0.694383144379 dLossOfReal: 0.602215 dLossOfFake: 0.786552 Time Elapsed: 1:09:06\n",
      "Iteration: 569 gLoss: 0.607785 averageDLoss 0.693543851376 dLossOfReal: 0.600592 dLossOfFake: 0.786495 Time Elapsed: 1:09:15\n",
      "Iteration: 570 gLoss: 0.607831 averageDLoss 0.693804860115 dLossOfReal: 0.601171 dLossOfFake: 0.786439 Time Elapsed: 1:09:23\n",
      "Iteration: 571 gLoss: 0.60788 averageDLoss 0.69406247139 dLossOfReal: 0.601747 dLossOfFake: 0.786378 Time Elapsed: 1:09:31\n",
      "Iteration: 572 gLoss: 0.60793 averageDLoss 0.694338679314 dLossOfReal: 0.602357 dLossOfFake: 0.786321 Time Elapsed: 1:09:39\n",
      "Iteration: 573 gLoss: 0.607977 averageDLoss 0.693766951561 dLossOfReal: 0.601272 dLossOfFake: 0.786262 Time Elapsed: 1:09:48\n",
      "Iteration: 574 gLoss: 0.608028 averageDLoss 0.694571614265 dLossOfReal: 0.602939 dLossOfFake: 0.786204 Time Elapsed: 1:09:56\n",
      "Iteration: 575 gLoss: 0.608075 averageDLoss 0.69425547123 dLossOfReal: 0.602365 dLossOfFake: 0.786146 Time Elapsed: 1:10:04\n",
      "Iteration: 576 gLoss: 0.608124 averageDLoss 0.694454669952 dLossOfReal: 0.602822 dLossOfFake: 0.786087 Time Elapsed: 1:10:13\n",
      "Iteration: 577 gLoss: 0.608168 averageDLoss 0.693752288818 dLossOfReal: 0.601471 dLossOfFake: 0.786034 Time Elapsed: 1:10:21\n",
      "Iteration: 578 gLoss: 0.608218 averageDLoss 0.695150732994 dLossOfReal: 0.604326 dLossOfFake: 0.785975 Time Elapsed: 1:10:29\n",
      "Iteration: 579 gLoss: 0.608266 averageDLoss 0.694257855415 dLossOfReal: 0.602597 dLossOfFake: 0.785919 Time Elapsed: 1:10:38\n",
      "Iteration: 580 gLoss: 0.608316 averageDLoss 0.69398277998 dLossOfReal: 0.602104 dLossOfFake: 0.785861 Time Elapsed: 1:10:46\n",
      "Iteration: 581 gLoss: 0.608359 averageDLoss 0.694576025009 dLossOfReal: 0.603345 dLossOfFake: 0.785807 Time Elapsed: 1:10:54\n",
      "Iteration: 582 gLoss: 0.608409 averageDLoss 0.694377779961 dLossOfReal: 0.603006 dLossOfFake: 0.785749 Time Elapsed: 1:11:03\n",
      "Iteration: 583 gLoss: 0.608455 averageDLoss 0.694088220596 dLossOfReal: 0.602481 dLossOfFake: 0.785695 Time Elapsed: 1:11:11\n",
      "Iteration: 584 gLoss: 0.608504 averageDLoss 0.693827390671 dLossOfReal: 0.602022 dLossOfFake: 0.785633 Time Elapsed: 1:11:20\n",
      "Iteration: 585 gLoss: 0.608551 averageDLoss 0.693850517273 dLossOfReal: 0.602121 dLossOfFake: 0.78558 Time Elapsed: 1:11:28\n",
      "Iteration: 586 gLoss: 0.608595 averageDLoss 0.693610489368 dLossOfReal: 0.601697 dLossOfFake: 0.785524 Time Elapsed: 1:11:37\n",
      "Iteration: 587 gLoss: 0.608643 averageDLoss 0.694380283356 dLossOfReal: 0.603292 dLossOfFake: 0.785468 Time Elapsed: 1:11:45\n",
      "Iteration: 588 gLoss: 0.608689 averageDLoss 0.693958282471 dLossOfReal: 0.602501 dLossOfFake: 0.785415 Time Elapsed: 1:11:54\n",
      "Iteration: 589 gLoss: 0.608736 averageDLoss 0.694784402847 dLossOfReal: 0.604211 dLossOfFake: 0.785358 Time Elapsed: 1:12:02\n",
      "Iteration: 590 gLoss: 0.608784 averageDLoss 0.694573879242 dLossOfReal: 0.603847 dLossOfFake: 0.785301 Time Elapsed: 1:12:11\n",
      "Iteration: 591 gLoss: 0.608829 averageDLoss 0.694334208965 dLossOfReal: 0.603422 dLossOfFake: 0.785246 Time Elapsed: 1:12:22\n",
      "Iteration: 592 gLoss: 0.608875 averageDLoss 0.694319427013 dLossOfReal: 0.603449 dLossOfFake: 0.78519 Time Elapsed: 1:12:30\n",
      "Iteration: 593 gLoss: 0.608924 averageDLoss 0.694820523262 dLossOfReal: 0.604508 dLossOfFake: 0.785133 Time Elapsed: 1:12:39\n",
      "Iteration: 594 gLoss: 0.608969 averageDLoss 0.6939650774 dLossOfReal: 0.60285 dLossOfFake: 0.78508 Time Elapsed: 1:12:48\n",
      "Iteration: 595 gLoss: 0.609018 averageDLoss 0.693983435631 dLossOfReal: 0.602947 dLossOfFake: 0.78502 Time Elapsed: 1:12:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 596 gLoss: 0.609061 averageDLoss 0.694547235966 dLossOfReal: 0.604123 dLossOfFake: 0.784972 Time Elapsed: 1:13:06\n",
      "Iteration: 597 gLoss: 0.609106 averageDLoss 0.693986177444 dLossOfReal: 0.603059 dLossOfFake: 0.784914 Time Elapsed: 1:13:14\n",
      "Iteration: 598 gLoss: 0.609153 averageDLoss 0.694584012032 dLossOfReal: 0.604311 dLossOfFake: 0.784857 Time Elapsed: 1:13:23\n",
      "Iteration: 599 gLoss: 0.609199 averageDLoss 0.694326400757 dLossOfReal: 0.603845 dLossOfFake: 0.784807 Time Elapsed: 1:13:31\n",
      "Iteration: 600 gLoss: 0.609244 averageDLoss 0.695006608963 dLossOfReal: 0.605263 dLossOfFake: 0.78475 Time Elapsed: 1:13:39\n",
      "Iteration: 601 gLoss: 0.609292 averageDLoss 0.694573521614 dLossOfReal: 0.604452 dLossOfFake: 0.784695 Time Elapsed: 1:13:48\n",
      "Iteration: 602 gLoss: 0.609337 averageDLoss 0.694310069084 dLossOfReal: 0.603977 dLossOfFake: 0.784643 Time Elapsed: 1:13:56\n",
      "Iteration: 603 gLoss: 0.60938 averageDLoss 0.693917632103 dLossOfReal: 0.603246 dLossOfFake: 0.784589 Time Elapsed: 1:14:05\n",
      "Iteration: 604 gLoss: 0.609425 averageDLoss 0.694100737572 dLossOfReal: 0.603665 dLossOfFake: 0.784536 Time Elapsed: 1:14:14\n",
      "Iteration: 605 gLoss: 0.609469 averageDLoss 0.694063782692 dLossOfReal: 0.603646 dLossOfFake: 0.784482 Time Elapsed: 1:14:22\n",
      "Iteration: 606 gLoss: 0.609515 averageDLoss 0.693291544914 dLossOfReal: 0.602153 dLossOfFake: 0.78443 Time Elapsed: 1:14:31\n",
      "Iteration: 607 gLoss: 0.60956 averageDLoss 0.694033503532 dLossOfReal: 0.603692 dLossOfFake: 0.784375 Time Elapsed: 1:14:39\n",
      "Iteration: 608 gLoss: 0.609607 averageDLoss 0.694156944752 dLossOfReal: 0.603993 dLossOfFake: 0.784321 Time Elapsed: 1:14:48\n",
      "Iteration: 609 gLoss: 0.60965 averageDLoss 0.693591833115 dLossOfReal: 0.602916 dLossOfFake: 0.784268 Time Elapsed: 1:14:56\n",
      "Iteration: 610 gLoss: 0.609695 averageDLoss 0.693813562393 dLossOfReal: 0.603412 dLossOfFake: 0.784215 Time Elapsed: 1:15:05\n",
      "Iteration: 611 gLoss: 0.60974 averageDLoss 0.694255113602 dLossOfReal: 0.604349 dLossOfFake: 0.784161 Time Elapsed: 1:15:13\n",
      "Iteration: 612 gLoss: 0.609783 averageDLoss 0.694012522697 dLossOfReal: 0.603915 dLossOfFake: 0.78411 Time Elapsed: 1:15:22\n",
      "Iteration: 613 gLoss: 0.609828 averageDLoss 0.694235563278 dLossOfReal: 0.604414 dLossOfFake: 0.784057 Time Elapsed: 1:15:30\n",
      "Iteration: 614 gLoss: 0.609871 averageDLoss 0.694233596325 dLossOfReal: 0.60446 dLossOfFake: 0.784007 Time Elapsed: 1:15:39\n",
      "Iteration: 615 gLoss: 0.609913 averageDLoss 0.693396568298 dLossOfReal: 0.602839 dLossOfFake: 0.783954 Time Elapsed: 1:15:48\n",
      "Iteration: 616 gLoss: 0.609959 averageDLoss 0.693659067154 dLossOfReal: 0.603418 dLossOfFake: 0.7839 Time Elapsed: 1:15:56\n",
      "Iteration: 617 gLoss: 0.610003 averageDLoss 0.693951010704 dLossOfReal: 0.604053 dLossOfFake: 0.783849 Time Elapsed: 1:16:05\n",
      "Iteration: 618 gLoss: 0.610045 averageDLoss 0.694687366486 dLossOfReal: 0.605577 dLossOfFake: 0.783798 Time Elapsed: 1:16:14\n",
      "Iteration: 619 gLoss: 0.610088 averageDLoss 0.693901896477 dLossOfReal: 0.604057 dLossOfFake: 0.783746 Time Elapsed: 1:16:22\n",
      "Iteration: 620 gLoss: 0.610131 averageDLoss 0.694133579731 dLossOfReal: 0.60457 dLossOfFake: 0.783697 Time Elapsed: 1:16:31\n",
      "Iteration: 621 gLoss: 0.610174 averageDLoss 0.693974494934 dLossOfReal: 0.604304 dLossOfFake: 0.783645 Time Elapsed: 1:16:40\n",
      "Iteration: 622 gLoss: 0.610218 averageDLoss 0.694614052773 dLossOfReal: 0.605635 dLossOfFake: 0.783593 Time Elapsed: 1:16:48\n",
      "Iteration: 623 gLoss: 0.610262 averageDLoss 0.694376826286 dLossOfReal: 0.605213 dLossOfFake: 0.78354 Time Elapsed: 1:16:57\n",
      "Iteration: 624 gLoss: 0.610305 averageDLoss 0.693756341934 dLossOfReal: 0.604025 dLossOfFake: 0.783488 Time Elapsed: 1:17:05\n",
      "Iteration: 625 gLoss: 0.610349 averageDLoss 0.693789243698 dLossOfReal: 0.604142 dLossOfFake: 0.783437 Time Elapsed: 1:17:14\n",
      "Iteration: 626 gLoss: 0.610393 averageDLoss 0.694038629532 dLossOfReal: 0.604692 dLossOfFake: 0.783385 Time Elapsed: 1:17:23\n",
      "Iteration: 627 gLoss: 0.610436 averageDLoss 0.694001436234 dLossOfReal: 0.604669 dLossOfFake: 0.783334 Time Elapsed: 1:17:31\n",
      "Iteration: 628 gLoss: 0.610478 averageDLoss 0.693853497505 dLossOfReal: 0.604423 dLossOfFake: 0.783284 Time Elapsed: 1:17:40\n",
      "Iteration: 629 gLoss: 0.610521 averageDLoss 0.694032013416 dLossOfReal: 0.604834 dLossOfFake: 0.78323 Time Elapsed: 1:17:49\n",
      "Iteration: 630 gLoss: 0.610564 averageDLoss 0.693967223167 dLossOfReal: 0.604754 dLossOfFake: 0.783181 Time Elapsed: 1:17:57\n",
      "Iteration: 631 gLoss: 0.610607 averageDLoss 0.694081664085 dLossOfReal: 0.605036 dLossOfFake: 0.783127 Time Elapsed: 1:18:06\n",
      "Iteration: 632 gLoss: 0.61065 averageDLoss 0.6942050457 dLossOfReal: 0.60533 dLossOfFake: 0.78308 Time Elapsed: 1:18:15\n",
      "Iteration: 633 gLoss: 0.610691 averageDLoss 0.693657875061 dLossOfReal: 0.604287 dLossOfFake: 0.783029 Time Elapsed: 1:18:23\n",
      "Iteration: 634 gLoss: 0.610731 averageDLoss 0.69434016943 dLossOfReal: 0.6057 dLossOfFake: 0.78298 Time Elapsed: 1:18:32\n",
      "Iteration: 635 gLoss: 0.610777 averageDLoss 0.693849682808 dLossOfReal: 0.60477 dLossOfFake: 0.782929 Time Elapsed: 1:18:41\n",
      "Iteration: 636 gLoss: 0.610818 averageDLoss 0.694062948227 dLossOfReal: 0.605248 dLossOfFake: 0.782878 Time Elapsed: 1:18:50\n",
      "Iteration: 637 gLoss: 0.610859 averageDLoss 0.693810462952 dLossOfReal: 0.604791 dLossOfFake: 0.78283 Time Elapsed: 1:18:58\n",
      "Iteration: 638 gLoss: 0.610902 averageDLoss 0.694009780884 dLossOfReal: 0.605241 dLossOfFake: 0.782779 Time Elapsed: 1:19:07\n",
      "Iteration: 639 gLoss: 0.610945 averageDLoss 0.693824648857 dLossOfReal: 0.604919 dLossOfFake: 0.78273 Time Elapsed: 1:19:16\n",
      "Iteration: 640 gLoss: 0.610986 averageDLoss 0.69340801239 dLossOfReal: 0.604138 dLossOfFake: 0.782678 Time Elapsed: 1:19:24\n",
      "Iteration: 641 gLoss: 0.611029 averageDLoss 0.694443106651 dLossOfReal: 0.606257 dLossOfFake: 0.782629 Time Elapsed: 1:19:33\n",
      "Iteration: 642 gLoss: 0.611069 averageDLoss 0.69319242239 dLossOfReal: 0.603806 dLossOfFake: 0.782579 Time Elapsed: 1:19:42\n",
      "Iteration: 643 gLoss: 0.611114 averageDLoss 0.693760156631 dLossOfReal: 0.604992 dLossOfFake: 0.782528 Time Elapsed: 1:19:50\n",
      "Iteration: 644 gLoss: 0.611154 averageDLoss 0.693985521793 dLossOfReal: 0.605488 dLossOfFake: 0.782483 Time Elapsed: 1:19:59\n",
      "Iteration: 645 gLoss: 0.611196 averageDLoss 0.693783521652 dLossOfReal: 0.605137 dLossOfFake: 0.78243 Time Elapsed: 1:20:08\n",
      "Iteration: 646 gLoss: 0.611238 averageDLoss 0.69387960434 dLossOfReal: 0.605378 dLossOfFake: 0.782382 Time Elapsed: 1:20:17\n",
      "Iteration: 647 gLoss: 0.611277 averageDLoss 0.693381667137 dLossOfReal: 0.60443 dLossOfFake: 0.782334 Time Elapsed: 1:20:25\n",
      "Iteration: 648 gLoss: 0.611319 averageDLoss 0.693957149982 dLossOfReal: 0.605629 dLossOfFake: 0.782285 Time Elapsed: 1:20:34\n",
      "Iteration: 649 gLoss: 0.611359 averageDLoss 0.694038927555 dLossOfReal: 0.605839 dLossOfFake: 0.782238 Time Elapsed: 1:20:43\n",
      "Iteration: 650 gLoss: 0.611399 averageDLoss 0.693723082542 dLossOfReal: 0.605257 dLossOfFake: 0.782189 Time Elapsed: 1:20:51\n",
      "Iteration: 651 gLoss: 0.611438 averageDLoss 0.69296079874 dLossOfReal: 0.603778 dLossOfFake: 0.782143 Time Elapsed: 1:21:00\n",
      "Iteration: 652 gLoss: 0.611481 averageDLoss 0.693956971169 dLossOfReal: 0.605822 dLossOfFake: 0.782092 Time Elapsed: 1:21:09\n",
      "Iteration: 653 gLoss: 0.61152 averageDLoss 0.693931102753 dLossOfReal: 0.605821 dLossOfFake: 0.782041 Time Elapsed: 1:21:18\n",
      "Iteration: 654 gLoss: 0.611561 averageDLoss 0.693616867065 dLossOfReal: 0.605237 dLossOfFake: 0.781997 Time Elapsed: 1:21:27\n",
      "Iteration: 655 gLoss: 0.611602 averageDLoss 0.693455159664 dLossOfReal: 0.604961 dLossOfFake: 0.781949 Time Elapsed: 1:21:36\n",
      "Iteration: 656 gLoss: 0.611643 averageDLoss 0.69394993782 dLossOfReal: 0.606 dLossOfFake: 0.7819 Time Elapsed: 1:21:44\n",
      "Iteration: 657 gLoss: 0.61168 averageDLoss 0.694193601608 dLossOfReal: 0.606533 dLossOfFake: 0.781854 Time Elapsed: 1:21:53\n",
      "Iteration: 658 gLoss: 0.611721 averageDLoss 0.693531394005 dLossOfReal: 0.605257 dLossOfFake: 0.781806 Time Elapsed: 1:22:02\n",
      "Iteration: 659 gLoss: 0.611761 averageDLoss 0.693885862827 dLossOfReal: 0.606014 dLossOfFake: 0.781758 Time Elapsed: 1:22:11\n",
      "Iteration: 660 gLoss: 0.611803 averageDLoss 0.693927526474 dLossOfReal: 0.606145 dLossOfFake: 0.78171 Time Elapsed: 1:22:19\n",
      "Iteration: 661 gLoss: 0.611844 averageDLoss 0.694163620472 dLossOfReal: 0.606665 dLossOfFake: 0.781662 Time Elapsed: 1:22:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 662 gLoss: 0.611884 averageDLoss 0.69406080246 dLossOfReal: 0.606509 dLossOfFake: 0.781612 Time Elapsed: 1:22:37\n",
      "Iteration: 663 gLoss: 0.611923 averageDLoss 0.693541765213 dLossOfReal: 0.605516 dLossOfFake: 0.781567 Time Elapsed: 1:22:46\n",
      "Iteration: 664 gLoss: 0.611962 averageDLoss 0.69350028038 dLossOfReal: 0.605481 dLossOfFake: 0.78152 Time Elapsed: 1:22:54\n",
      "Iteration: 665 gLoss: 0.612003 averageDLoss 0.69334512949 dLossOfReal: 0.605219 dLossOfFake: 0.781471 Time Elapsed: 1:23:03\n",
      "Iteration: 666 gLoss: 0.612044 averageDLoss 0.693602323532 dLossOfReal: 0.60578 dLossOfFake: 0.781425 Time Elapsed: 1:23:12\n",
      "Iteration: 667 gLoss: 0.612083 averageDLoss 0.6936429739 dLossOfReal: 0.605908 dLossOfFake: 0.781378 Time Elapsed: 1:23:21\n",
      "Iteration: 668 gLoss: 0.612121 averageDLoss 0.694463014603 dLossOfReal: 0.607595 dLossOfFake: 0.781332 Time Elapsed: 1:23:30\n",
      "Iteration: 669 gLoss: 0.612157 averageDLoss 0.693825721741 dLossOfReal: 0.606363 dLossOfFake: 0.781288 Time Elapsed: 1:23:38\n",
      "Iteration: 670 gLoss: 0.6122 averageDLoss 0.694237351418 dLossOfReal: 0.607234 dLossOfFake: 0.78124 Time Elapsed: 1:23:47\n",
      "Iteration: 671 gLoss: 0.612238 averageDLoss 0.694254994392 dLossOfReal: 0.607316 dLossOfFake: 0.781194 Time Elapsed: 1:23:56\n",
      "Iteration: 672 gLoss: 0.612276 averageDLoss 0.693849265575 dLossOfReal: 0.606553 dLossOfFake: 0.781145 Time Elapsed: 1:24:05\n",
      "Iteration: 673 gLoss: 0.61232 averageDLoss 0.694296240807 dLossOfReal: 0.607495 dLossOfFake: 0.781097 Time Elapsed: 1:24:14\n",
      "Iteration: 674 gLoss: 0.61236 averageDLoss 0.693729281425 dLossOfReal: 0.606409 dLossOfFake: 0.78105 Time Elapsed: 1:24:23\n",
      "Iteration: 675 gLoss: 0.612399 averageDLoss 0.693129301071 dLossOfReal: 0.605255 dLossOfFake: 0.781004 Time Elapsed: 1:24:31\n",
      "Iteration: 676 gLoss: 0.61244 averageDLoss 0.693506598473 dLossOfReal: 0.606057 dLossOfFake: 0.780956 Time Elapsed: 1:24:40\n",
      "Iteration: 677 gLoss: 0.612479 averageDLoss 0.693735599518 dLossOfReal: 0.60656 dLossOfFake: 0.780912 Time Elapsed: 1:24:49\n",
      "Iteration: 678 gLoss: 0.612517 averageDLoss 0.692754149437 dLossOfReal: 0.604643 dLossOfFake: 0.780866 Time Elapsed: 1:24:58\n",
      "Iteration: 679 gLoss: 0.612555 averageDLoss 0.6937520504 dLossOfReal: 0.606686 dLossOfFake: 0.780818 Time Elapsed: 1:25:07\n",
      "Iteration: 680 gLoss: 0.612594 averageDLoss 0.693389177322 dLossOfReal: 0.606005 dLossOfFake: 0.780774 Time Elapsed: 1:25:16\n",
      "Iteration: 681 gLoss: 0.61263 averageDLoss 0.693018078804 dLossOfReal: 0.605303 dLossOfFake: 0.780733 Time Elapsed: 1:25:25\n",
      "Iteration: 682 gLoss: 0.612668 averageDLoss 0.694245636463 dLossOfReal: 0.607804 dLossOfFake: 0.780688 Time Elapsed: 1:25:34\n",
      "Iteration: 683 gLoss: 0.612705 averageDLoss 0.693408370018 dLossOfReal: 0.606177 dLossOfFake: 0.78064 Time Elapsed: 1:25:42\n",
      "Iteration: 684 gLoss: 0.612745 averageDLoss 0.693174481392 dLossOfReal: 0.605756 dLossOfFake: 0.780593 Time Elapsed: 1:25:51\n",
      "Iteration: 685 gLoss: 0.612785 averageDLoss 0.693103790283 dLossOfReal: 0.60566 dLossOfFake: 0.780548 Time Elapsed: 1:26:00\n",
      "Iteration: 686 gLoss: 0.61282 averageDLoss 0.693901836872 dLossOfReal: 0.607299 dLossOfFake: 0.780505 Time Elapsed: 1:26:09\n",
      "Iteration: 687 gLoss: 0.612862 averageDLoss 0.692941486835 dLossOfReal: 0.605427 dLossOfFake: 0.780456 Time Elapsed: 1:26:18\n",
      "Iteration: 688 gLoss: 0.612899 averageDLoss 0.693296909332 dLossOfReal: 0.606182 dLossOfFake: 0.780412 Time Elapsed: 1:26:27\n",
      "Iteration: 689 gLoss: 0.612935 averageDLoss 0.694001197815 dLossOfReal: 0.607635 dLossOfFake: 0.780367 Time Elapsed: 1:26:36\n",
      "Iteration: 690 gLoss: 0.612974 averageDLoss 0.69311273098 dLossOfReal: 0.605903 dLossOfFake: 0.780323 Time Elapsed: 1:26:45\n",
      "Iteration: 691 gLoss: 0.613015 averageDLoss 0.693695068359 dLossOfReal: 0.607112 dLossOfFake: 0.780278 Time Elapsed: 1:26:54\n",
      "Iteration: 692 gLoss: 0.613053 averageDLoss 0.692995965481 dLossOfReal: 0.605761 dLossOfFake: 0.780231 Time Elapsed: 1:27:03\n",
      "Iteration: 693 gLoss: 0.613089 averageDLoss 0.692883253098 dLossOfReal: 0.605578 dLossOfFake: 0.780189 Time Elapsed: 1:27:12\n",
      "Iteration: 694 gLoss: 0.613128 averageDLoss 0.693329513073 dLossOfReal: 0.606518 dLossOfFake: 0.780141 Time Elapsed: 1:27:21\n",
      "Iteration: 695 gLoss: 0.613164 averageDLoss 0.693465530872 dLossOfReal: 0.606832 dLossOfFake: 0.7801 Time Elapsed: 1:27:29\n",
      "Iteration: 696 gLoss: 0.613201 averageDLoss 0.693535804749 dLossOfReal: 0.607016 dLossOfFake: 0.780055 Time Elapsed: 1:27:38\n",
      "Iteration: 697 gLoss: 0.613238 averageDLoss 0.693356633186 dLossOfReal: 0.606705 dLossOfFake: 0.780009 Time Elapsed: 1:27:48\n",
      "Iteration: 698 gLoss: 0.613278 averageDLoss 0.693392336369 dLossOfReal: 0.60682 dLossOfFake: 0.779965 Time Elapsed: 1:27:56\n",
      "Iteration: 699 gLoss: 0.613318 averageDLoss 0.69323849678 dLossOfReal: 0.606556 dLossOfFake: 0.779921 Time Elapsed: 1:28:05\n",
      "Iteration: 700 gLoss: 0.613352 averageDLoss 0.693015515804 dLossOfReal: 0.606155 dLossOfFake: 0.779876 Time Elapsed: 1:28:14\n",
      "Iteration: 701 gLoss: 0.613388 averageDLoss 0.694076776505 dLossOfReal: 0.608319 dLossOfFake: 0.779835 Time Elapsed: 1:28:23\n",
      "Iteration: 702 gLoss: 0.613425 averageDLoss 0.69395762682 dLossOfReal: 0.608123 dLossOfFake: 0.779792 Time Elapsed: 1:28:32\n",
      "Iteration: 703 gLoss: 0.613462 averageDLoss 0.69382250309 dLossOfReal: 0.607898 dLossOfFake: 0.779747 Time Elapsed: 1:28:41\n",
      "Iteration: 704 gLoss: 0.6135 averageDLoss 0.69323348999 dLossOfReal: 0.606768 dLossOfFake: 0.779699 Time Elapsed: 1:28:50\n",
      "Iteration: 705 gLoss: 0.613538 averageDLoss 0.69348692894 dLossOfReal: 0.607317 dLossOfFake: 0.779657 Time Elapsed: 1:28:58\n",
      "Iteration: 706 gLoss: 0.613576 averageDLoss 0.693674147129 dLossOfReal: 0.607735 dLossOfFake: 0.779614 Time Elapsed: 1:29:07\n",
      "Iteration: 707 gLoss: 0.613614 averageDLoss 0.693940401077 dLossOfReal: 0.608313 dLossOfFake: 0.779568 Time Elapsed: 1:29:16\n",
      "Iteration: 708 gLoss: 0.613653 averageDLoss 0.692528009415 dLossOfReal: 0.605535 dLossOfFake: 0.779521 Time Elapsed: 1:29:25\n",
      "Iteration: 709 gLoss: 0.61369 averageDLoss 0.693442463875 dLossOfReal: 0.607409 dLossOfFake: 0.779476 Time Elapsed: 1:29:34\n",
      "Iteration: 710 gLoss: 0.613727 averageDLoss 0.69285684824 dLossOfReal: 0.60628 dLossOfFake: 0.779434 Time Elapsed: 1:29:43\n",
      "Iteration: 711 gLoss: 0.613765 averageDLoss 0.693134725094 dLossOfReal: 0.606881 dLossOfFake: 0.779389 Time Elapsed: 1:29:51\n",
      "Iteration: 712 gLoss: 0.613802 averageDLoss 0.69328892231 dLossOfReal: 0.607232 dLossOfFake: 0.779346 Time Elapsed: 1:30:00\n",
      "Iteration: 713 gLoss: 0.613838 averageDLoss 0.693206429482 dLossOfReal: 0.607107 dLossOfFake: 0.779306 Time Elapsed: 1:30:09\n",
      "Iteration: 714 gLoss: 0.613874 averageDLoss 0.69260340929 dLossOfReal: 0.605947 dLossOfFake: 0.77926 Time Elapsed: 1:30:18\n",
      "Iteration: 715 gLoss: 0.613909 averageDLoss 0.693774402142 dLossOfReal: 0.60833 dLossOfFake: 0.779218 Time Elapsed: 1:30:27\n",
      "Iteration: 716 gLoss: 0.613943 averageDLoss 0.693480849266 dLossOfReal: 0.607782 dLossOfFake: 0.779179 Time Elapsed: 1:30:36\n",
      "Iteration: 717 gLoss: 0.613979 averageDLoss 0.693983793259 dLossOfReal: 0.608831 dLossOfFake: 0.779136 Time Elapsed: 1:30:45\n",
      "Iteration: 718 gLoss: 0.614016 averageDLoss 0.693071961403 dLossOfReal: 0.60705 dLossOfFake: 0.779094 Time Elapsed: 1:30:54\n",
      "Iteration: 719 gLoss: 0.614052 averageDLoss 0.693652272224 dLossOfReal: 0.608255 dLossOfFake: 0.77905 Time Elapsed: 1:31:02\n",
      "Iteration: 720 gLoss: 0.614089 averageDLoss 0.693670749664 dLossOfReal: 0.608335 dLossOfFake: 0.779007 Time Elapsed: 1:31:11\n",
      "Iteration: 721 gLoss: 0.614123 averageDLoss 0.69345241785 dLossOfReal: 0.60794 dLossOfFake: 0.778965 Time Elapsed: 1:31:21\n",
      "Iteration: 722 gLoss: 0.614158 averageDLoss 0.693585276604 dLossOfReal: 0.608246 dLossOfFake: 0.778924 Time Elapsed: 1:31:30\n",
      "Iteration: 723 gLoss: 0.614196 averageDLoss 0.692907452583 dLossOfReal: 0.606934 dLossOfFake: 0.77888 Time Elapsed: 1:31:39\n",
      "Iteration: 724 gLoss: 0.614229 averageDLoss 0.693644165993 dLossOfReal: 0.608447 dLossOfFake: 0.778841 Time Elapsed: 1:31:47\n",
      "Iteration: 725 gLoss: 0.614263 averageDLoss 0.693143844604 dLossOfReal: 0.607486 dLossOfFake: 0.778802 Time Elapsed: 1:31:56\n",
      "Iteration: 726 gLoss: 0.6143 averageDLoss 0.693453788757 dLossOfReal: 0.608151 dLossOfFake: 0.778757 Time Elapsed: 1:32:05\n",
      "Iteration: 727 gLoss: 0.61434 averageDLoss 0.69284594059 dLossOfReal: 0.606982 dLossOfFake: 0.77871 Time Elapsed: 1:32:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 728 gLoss: 0.614375 averageDLoss 0.693333029747 dLossOfReal: 0.607997 dLossOfFake: 0.778669 Time Elapsed: 1:32:23\n",
      "Iteration: 729 gLoss: 0.614411 averageDLoss 0.693466424942 dLossOfReal: 0.608305 dLossOfFake: 0.778628 Time Elapsed: 1:32:32\n",
      "Iteration: 730 gLoss: 0.614448 averageDLoss 0.693053364754 dLossOfReal: 0.607522 dLossOfFake: 0.778585 Time Elapsed: 1:32:41\n",
      "Iteration: 731 gLoss: 0.614483 averageDLoss 0.693187236786 dLossOfReal: 0.607832 dLossOfFake: 0.778543 Time Elapsed: 1:32:49\n",
      "Iteration: 732 gLoss: 0.614515 averageDLoss 0.693102478981 dLossOfReal: 0.607702 dLossOfFake: 0.778503 Time Elapsed: 1:32:58\n",
      "Iteration: 733 gLoss: 0.614551 averageDLoss 0.693296551704 dLossOfReal: 0.608129 dLossOfFake: 0.778464 Time Elapsed: 1:33:07\n",
      "Iteration: 734 gLoss: 0.614589 averageDLoss 0.693383574486 dLossOfReal: 0.608347 dLossOfFake: 0.77842 Time Elapsed: 1:33:16\n",
      "Iteration: 735 gLoss: 0.614622 averageDLoss 0.693167448044 dLossOfReal: 0.607957 dLossOfFake: 0.778378 Time Elapsed: 1:33:26\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "for i in range(0,50000):\n",
    "    currentDLossOfReal = sess.run(dLossOfReal,{z:newZBatch(batchSize),x:newXBatch(batchSize)})\n",
    "    currentDLossOfFake = sess.run(dLossOfFake,{z:newZBatch(batchSize),x:newXBatch(batchSize)})\n",
    "    averageDLoss = (currentDLossOfReal + currentDLossOfFake) / 2\n",
    "    currentGLoss = sess.run(gLoss,{z:newZBatch(batchSize)})\n",
    "    trainingSchedule = round((i/25)%2)\n",
    "\n",
    "    if currentDLossOfReal > 0.4:\n",
    "        sess.run(trainDReal,{x:newXBatch(batchSize)})\n",
    "    if currentDLossOfFake > 0.75:\n",
    "        sess.run(trainDFake,{z:newZBatch(batchSize)})\n",
    "    if currentGLoss > 0.4:\n",
    "        sess.run(trainG,{z:newZBatch(batchSize)})\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        print('Iteration:',i,'gLoss:',currentGLoss, 'averageDLoss',averageDLoss,'dLossOfReal:',currentDLossOfReal,'dLossOfFake:',currentDLossOfFake,'Time Elapsed:',timedelta(seconds=int(round(time.time()-startTime))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x284804272e8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x284802ff940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zNoise = newZBatch(1)\n",
    "newImage = sess.run(generator(z),{z:zNoise})\n",
    "#print(newImage.shape)\n",
    "newImage = newImage.reshape(28,28)\n",
    "plt.imshow(newImage,cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30575073]\n",
      " [ 0.29419795]\n",
      " [ 0.3069216 ]\n",
      " [ 0.29575095]\n",
      " [ 0.31150776]\n",
      " [ 0.3125132 ]\n",
      " [ 0.29613104]\n",
      " [ 0.30172464]\n",
      " [ 0.29462576]\n",
      " [ 0.30902877]\n",
      " [ 0.31142461]\n",
      " [ 0.29888433]\n",
      " [ 0.33120787]\n",
      " [ 0.30537266]\n",
      " [ 0.29893464]\n",
      " [ 0.2985239 ]\n",
      " [ 0.30552992]\n",
      " [ 0.31033278]\n",
      " [ 0.28881609]\n",
      " [ 0.33789101]\n",
      " [ 0.31463072]\n",
      " [ 0.30034533]\n",
      " [ 0.31149659]\n",
      " [ 0.33450598]\n",
      " [ 0.31559822]\n",
      " [ 0.28027785]\n",
      " [ 0.29343262]\n",
      " [ 0.30685645]\n",
      " [ 0.31047323]\n",
      " [ 0.31032825]\n",
      " [ 0.29821661]\n",
      " [ 0.31114647]\n",
      " [ 0.32596108]\n",
      " [ 0.31017369]\n",
      " [ 0.331117  ]\n",
      " [ 0.32217744]\n",
      " [ 0.31732753]\n",
      " [ 0.2825987 ]\n",
      " [ 0.3253459 ]\n",
      " [ 0.31300032]\n",
      " [ 0.31923115]\n",
      " [ 0.31595457]\n",
      " [ 0.28602162]\n",
      " [ 0.28436086]\n",
      " [ 0.29468486]\n",
      " [ 0.3252748 ]\n",
      " [ 0.2953378 ]\n",
      " [ 0.29643723]\n",
      " [ 0.28048572]\n",
      " [ 0.28844455]]\n",
      "[[ 0.31744763]\n",
      " [ 0.28927538]\n",
      " [ 0.32738367]\n",
      " [ 0.30505207]\n",
      " [ 0.3042013 ]\n",
      " [ 0.3098726 ]\n",
      " [ 0.29750887]\n",
      " [ 0.30298284]\n",
      " [ 0.31581447]\n",
      " [ 0.30496174]\n",
      " [ 0.31688878]\n",
      " [ 0.30536461]\n",
      " [ 0.31470212]\n",
      " [ 0.30789131]\n",
      " [ 0.29415703]\n",
      " [ 0.29031095]\n",
      " [ 0.30546111]\n",
      " [ 0.31858379]\n",
      " [ 0.31118071]\n",
      " [ 0.31654388]\n",
      " [ 0.30596337]\n",
      " [ 0.30138516]\n",
      " [ 0.31314513]\n",
      " [ 0.30784428]\n",
      " [ 0.31425479]\n",
      " [ 0.29695976]\n",
      " [ 0.29393718]\n",
      " [ 0.29076755]\n",
      " [ 0.30429742]\n",
      " [ 0.29321167]\n",
      " [ 0.30421233]\n",
      " [ 0.30332816]\n",
      " [ 0.31131294]\n",
      " [ 0.29756919]\n",
      " [ 0.32003528]\n",
      " [ 0.31799075]\n",
      " [ 0.31106773]\n",
      " [ 0.31533667]\n",
      " [ 0.30815971]\n",
      " [ 0.31414267]\n",
      " [ 0.29733256]\n",
      " [ 0.31881806]\n",
      " [ 0.28091526]\n",
      " [ 0.30101219]\n",
      " [ 0.30313817]\n",
      " [ 0.30817303]\n",
      " [ 0.29392189]\n",
      " [ 0.29767236]\n",
      " [ 0.30310276]\n",
      " [ 0.30402991]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(discriminator(x),{x:newXBatch(batchSize)}))\n",
    "print(sess.run(discriminator(generator(z)),{z:newZBatch(batchSize)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstGB0 = sess.run(gb0)\n",
    "for i in range(0,50):\n",
    "    sess.run(trainG,{z:newZBatch(batchSize)})\n",
    "print(sess.run(gb0) - firstGB0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstGB0 = sess.run(gb0)\n",
    "for i in range(0,50):\n",
    "    sess.run(trainDFake,{z:newZBatch(batchSize)})\n",
    "print(sess.run(gb0) - firstGB0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.save(sess,'C:\\Preston\\MNIST GAN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
